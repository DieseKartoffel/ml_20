{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#must be very first statement\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[[ 59,  62,  63],\n",
       "           [ 43,  46,  45],\n",
       "           [ 50,  48,  43],\n",
       "           ...,\n",
       "           [158, 132, 108],\n",
       "           [152, 125, 102],\n",
       "           [148, 124, 103]],\n",
       "  \n",
       "          [[ 16,  20,  20],\n",
       "           [  0,   0,   0],\n",
       "           [ 18,   8,   0],\n",
       "           ...,\n",
       "           [123,  88,  55],\n",
       "           [119,  83,  50],\n",
       "           [122,  87,  57]],\n",
       "  \n",
       "          [[ 25,  24,  21],\n",
       "           [ 16,   7,   0],\n",
       "           [ 49,  27,   8],\n",
       "           ...,\n",
       "           [118,  84,  50],\n",
       "           [120,  84,  50],\n",
       "           [109,  73,  42]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[208, 170,  96],\n",
       "           [201, 153,  34],\n",
       "           [198, 161,  26],\n",
       "           ...,\n",
       "           [160, 133,  70],\n",
       "           [ 56,  31,   7],\n",
       "           [ 53,  34,  20]],\n",
       "  \n",
       "          [[180, 139,  96],\n",
       "           [173, 123,  42],\n",
       "           [186, 144,  30],\n",
       "           ...,\n",
       "           [184, 148,  94],\n",
       "           [ 97,  62,  34],\n",
       "           [ 83,  53,  34]],\n",
       "  \n",
       "          [[177, 144, 116],\n",
       "           [168, 129,  94],\n",
       "           [179, 142,  87],\n",
       "           ...,\n",
       "           [216, 184, 140],\n",
       "           [151, 118,  84],\n",
       "           [123,  92,  72]]],\n",
       "  \n",
       "  \n",
       "         [[[154, 177, 187],\n",
       "           [126, 137, 136],\n",
       "           [105, 104,  95],\n",
       "           ...,\n",
       "           [ 91,  95,  71],\n",
       "           [ 87,  90,  71],\n",
       "           [ 79,  81,  70]],\n",
       "  \n",
       "          [[140, 160, 169],\n",
       "           [145, 153, 154],\n",
       "           [125, 125, 118],\n",
       "           ...,\n",
       "           [ 96,  99,  78],\n",
       "           [ 77,  80,  62],\n",
       "           [ 71,  73,  61]],\n",
       "  \n",
       "          [[140, 155, 164],\n",
       "           [139, 146, 149],\n",
       "           [115, 115, 112],\n",
       "           ...,\n",
       "           [ 79,  82,  64],\n",
       "           [ 68,  70,  55],\n",
       "           [ 67,  69,  55]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[175, 167, 166],\n",
       "           [156, 154, 160],\n",
       "           [154, 160, 170],\n",
       "           ...,\n",
       "           [ 42,  34,  36],\n",
       "           [ 61,  53,  57],\n",
       "           [ 93,  83,  91]],\n",
       "  \n",
       "          [[165, 154, 128],\n",
       "           [156, 152, 130],\n",
       "           [159, 161, 142],\n",
       "           ...,\n",
       "           [103,  93,  96],\n",
       "           [123, 114, 120],\n",
       "           [131, 121, 131]],\n",
       "  \n",
       "          [[163, 148, 120],\n",
       "           [158, 148, 122],\n",
       "           [163, 156, 133],\n",
       "           ...,\n",
       "           [143, 133, 139],\n",
       "           [143, 134, 142],\n",
       "           [143, 133, 144]]],\n",
       "  \n",
       "  \n",
       "         [[[255, 255, 255],\n",
       "           [253, 253, 253],\n",
       "           [253, 253, 253],\n",
       "           ...,\n",
       "           [253, 253, 253],\n",
       "           [253, 253, 253],\n",
       "           [253, 253, 253]],\n",
       "  \n",
       "          [[255, 255, 255],\n",
       "           [255, 255, 255],\n",
       "           [255, 255, 255],\n",
       "           ...,\n",
       "           [255, 255, 255],\n",
       "           [255, 255, 255],\n",
       "           [255, 255, 255]],\n",
       "  \n",
       "          [[255, 255, 255],\n",
       "           [254, 254, 254],\n",
       "           [254, 254, 254],\n",
       "           ...,\n",
       "           [254, 254, 254],\n",
       "           [254, 254, 254],\n",
       "           [254, 254, 254]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[113, 120, 112],\n",
       "           [111, 118, 111],\n",
       "           [105, 112, 106],\n",
       "           ...,\n",
       "           [ 72,  81,  80],\n",
       "           [ 72,  80,  79],\n",
       "           [ 72,  80,  79]],\n",
       "  \n",
       "          [[111, 118, 110],\n",
       "           [104, 111, 104],\n",
       "           [ 99, 106,  98],\n",
       "           ...,\n",
       "           [ 68,  75,  73],\n",
       "           [ 70,  76,  75],\n",
       "           [ 78,  84,  82]],\n",
       "  \n",
       "          [[106, 113, 105],\n",
       "           [ 99, 106,  98],\n",
       "           [ 95, 102,  94],\n",
       "           ...,\n",
       "           [ 78,  85,  83],\n",
       "           [ 79,  85,  83],\n",
       "           [ 80,  86,  84]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[ 35, 178, 235],\n",
       "           [ 40, 176, 239],\n",
       "           [ 42, 176, 241],\n",
       "           ...,\n",
       "           [ 99, 177, 219],\n",
       "           [ 79, 147, 197],\n",
       "           [ 89, 148, 189]],\n",
       "  \n",
       "          [[ 57, 182, 234],\n",
       "           [ 44, 184, 250],\n",
       "           [ 50, 183, 240],\n",
       "           ...,\n",
       "           [156, 182, 200],\n",
       "           [141, 177, 206],\n",
       "           [116, 149, 175]],\n",
       "  \n",
       "          [[ 98, 197, 237],\n",
       "           [ 64, 189, 252],\n",
       "           [ 69, 192, 245],\n",
       "           ...,\n",
       "           [188, 195, 206],\n",
       "           [119, 135, 147],\n",
       "           [ 61,  79,  90]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 73,  79,  77],\n",
       "           [ 53,  63,  68],\n",
       "           [ 54,  68,  80],\n",
       "           ...,\n",
       "           [ 17,  40,  64],\n",
       "           [ 21,  36,  51],\n",
       "           [ 33,  48,  49]],\n",
       "  \n",
       "          [[ 61,  68,  75],\n",
       "           [ 55,  70,  86],\n",
       "           [ 57,  79, 103],\n",
       "           ...,\n",
       "           [ 24,  48,  72],\n",
       "           [ 17,  35,  53],\n",
       "           [  7,  23,  32]],\n",
       "  \n",
       "          [[ 44,  56,  73],\n",
       "           [ 46,  66,  88],\n",
       "           [ 49,  77, 105],\n",
       "           ...,\n",
       "           [ 27,  52,  77],\n",
       "           [ 21,  43,  66],\n",
       "           [ 12,  31,  50]]],\n",
       "  \n",
       "  \n",
       "         [[[189, 211, 240],\n",
       "           [186, 208, 236],\n",
       "           [185, 207, 235],\n",
       "           ...,\n",
       "           [175, 195, 224],\n",
       "           [172, 194, 222],\n",
       "           [169, 194, 220]],\n",
       "  \n",
       "          [[194, 210, 239],\n",
       "           [191, 207, 236],\n",
       "           [190, 206, 235],\n",
       "           ...,\n",
       "           [173, 192, 220],\n",
       "           [171, 191, 218],\n",
       "           [167, 190, 216]],\n",
       "  \n",
       "          [[208, 219, 244],\n",
       "           [205, 216, 240],\n",
       "           [204, 215, 239],\n",
       "           ...,\n",
       "           [175, 191, 217],\n",
       "           [172, 190, 216],\n",
       "           [169, 191, 215]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[207, 199, 181],\n",
       "           [203, 195, 175],\n",
       "           [203, 196, 173],\n",
       "           ...,\n",
       "           [135, 132, 127],\n",
       "           [162, 158, 150],\n",
       "           [168, 163, 151]],\n",
       "  \n",
       "          [[198, 190, 170],\n",
       "           [189, 181, 159],\n",
       "           [180, 172, 147],\n",
       "           ...,\n",
       "           [178, 171, 160],\n",
       "           [175, 169, 156],\n",
       "           [175, 169, 154]],\n",
       "  \n",
       "          [[198, 189, 173],\n",
       "           [189, 181, 162],\n",
       "           [178, 170, 149],\n",
       "           ...,\n",
       "           [195, 184, 169],\n",
       "           [196, 189, 171],\n",
       "           [195, 190, 171]]],\n",
       "  \n",
       "  \n",
       "         [[[229, 229, 239],\n",
       "           [236, 237, 247],\n",
       "           [234, 236, 247],\n",
       "           ...,\n",
       "           [217, 219, 233],\n",
       "           [221, 223, 234],\n",
       "           [222, 223, 233]],\n",
       "  \n",
       "          [[222, 221, 229],\n",
       "           [239, 239, 249],\n",
       "           [233, 234, 246],\n",
       "           ...,\n",
       "           [223, 223, 236],\n",
       "           [227, 228, 238],\n",
       "           [210, 211, 220]],\n",
       "  \n",
       "          [[213, 206, 211],\n",
       "           [234, 232, 239],\n",
       "           [231, 233, 244],\n",
       "           ...,\n",
       "           [220, 220, 232],\n",
       "           [220, 219, 232],\n",
       "           [202, 203, 215]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[150, 143, 135],\n",
       "           [140, 135, 127],\n",
       "           [132, 127, 120],\n",
       "           ...,\n",
       "           [224, 222, 218],\n",
       "           [230, 228, 225],\n",
       "           [241, 241, 238]],\n",
       "  \n",
       "          [[137, 132, 126],\n",
       "           [130, 127, 120],\n",
       "           [125, 121, 115],\n",
       "           ...,\n",
       "           [181, 180, 178],\n",
       "           [202, 201, 198],\n",
       "           [212, 211, 207]],\n",
       "  \n",
       "          [[122, 119, 114],\n",
       "           [118, 116, 110],\n",
       "           [120, 116, 111],\n",
       "           ...,\n",
       "           [179, 177, 173],\n",
       "           [164, 164, 162],\n",
       "           [163, 163, 161]]]], dtype=uint8),\n",
       "  array([[6],\n",
       "         [9],\n",
       "         [9],\n",
       "         ...,\n",
       "         [9],\n",
       "         [1],\n",
       "         [1]], dtype=uint8)),\n",
       " (array([[[[158, 112,  49],\n",
       "           [159, 111,  47],\n",
       "           [165, 116,  51],\n",
       "           ...,\n",
       "           [137,  95,  36],\n",
       "           [126,  91,  36],\n",
       "           [116,  85,  33]],\n",
       "  \n",
       "          [[152, 112,  51],\n",
       "           [151, 110,  40],\n",
       "           [159, 114,  45],\n",
       "           ...,\n",
       "           [136,  95,  31],\n",
       "           [125,  91,  32],\n",
       "           [119,  88,  34]],\n",
       "  \n",
       "          [[151, 110,  47],\n",
       "           [151, 109,  33],\n",
       "           [158, 111,  36],\n",
       "           ...,\n",
       "           [139,  98,  34],\n",
       "           [130,  95,  34],\n",
       "           [120,  89,  33]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 68, 124, 177],\n",
       "           [ 42, 100, 148],\n",
       "           [ 31,  88, 137],\n",
       "           ...,\n",
       "           [ 38,  97, 146],\n",
       "           [ 13,  64, 108],\n",
       "           [ 40,  85, 127]],\n",
       "  \n",
       "          [[ 61, 116, 168],\n",
       "           [ 49, 102, 148],\n",
       "           [ 35,  85, 132],\n",
       "           ...,\n",
       "           [ 26,  82, 130],\n",
       "           [ 29,  82, 126],\n",
       "           [ 20,  64, 107]],\n",
       "  \n",
       "          [[ 54, 107, 160],\n",
       "           [ 56, 105, 149],\n",
       "           [ 45,  89, 132],\n",
       "           ...,\n",
       "           [ 24,  77, 124],\n",
       "           [ 34,  84, 129],\n",
       "           [ 21,  67, 110]]],\n",
       "  \n",
       "  \n",
       "         [[[235, 235, 235],\n",
       "           [231, 231, 231],\n",
       "           [232, 232, 232],\n",
       "           ...,\n",
       "           [233, 233, 233],\n",
       "           [233, 233, 233],\n",
       "           [232, 232, 232]],\n",
       "  \n",
       "          [[238, 238, 238],\n",
       "           [235, 235, 235],\n",
       "           [235, 235, 235],\n",
       "           ...,\n",
       "           [236, 236, 236],\n",
       "           [236, 236, 236],\n",
       "           [235, 235, 235]],\n",
       "  \n",
       "          [[237, 237, 237],\n",
       "           [234, 234, 234],\n",
       "           [234, 234, 234],\n",
       "           ...,\n",
       "           [235, 235, 235],\n",
       "           [235, 235, 235],\n",
       "           [234, 234, 234]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 87,  99,  89],\n",
       "           [ 43,  51,  37],\n",
       "           [ 19,  23,  11],\n",
       "           ...,\n",
       "           [169, 184, 179],\n",
       "           [182, 197, 193],\n",
       "           [188, 202, 201]],\n",
       "  \n",
       "          [[ 82,  96,  82],\n",
       "           [ 46,  57,  36],\n",
       "           [ 36,  44,  22],\n",
       "           ...,\n",
       "           [174, 189, 183],\n",
       "           [185, 200, 196],\n",
       "           [187, 202, 200]],\n",
       "  \n",
       "          [[ 85, 101,  83],\n",
       "           [ 62,  75,  48],\n",
       "           [ 58,  67,  38],\n",
       "           ...,\n",
       "           [168, 183, 178],\n",
       "           [180, 195, 191],\n",
       "           [186, 200, 199]]],\n",
       "  \n",
       "  \n",
       "         [[[158, 190, 222],\n",
       "           [158, 187, 218],\n",
       "           [139, 166, 194],\n",
       "           ...,\n",
       "           [228, 231, 234],\n",
       "           [237, 239, 243],\n",
       "           [238, 241, 246]],\n",
       "  \n",
       "          [[170, 200, 229],\n",
       "           [172, 199, 226],\n",
       "           [151, 176, 201],\n",
       "           ...,\n",
       "           [232, 232, 236],\n",
       "           [246, 246, 250],\n",
       "           [246, 247, 251]],\n",
       "  \n",
       "          [[174, 201, 225],\n",
       "           [176, 200, 222],\n",
       "           [157, 179, 199],\n",
       "           ...,\n",
       "           [230, 229, 232],\n",
       "           [250, 249, 251],\n",
       "           [245, 244, 247]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 31,  40,  45],\n",
       "           [ 30,  39,  44],\n",
       "           [ 26,  35,  40],\n",
       "           ...,\n",
       "           [ 37,  40,  46],\n",
       "           [  9,  13,  14],\n",
       "           [  4,   7,   5]],\n",
       "  \n",
       "          [[ 23,  34,  39],\n",
       "           [ 27,  38,  43],\n",
       "           [ 25,  36,  41],\n",
       "           ...,\n",
       "           [ 19,  20,  24],\n",
       "           [  4,   6,   3],\n",
       "           [  5,   7,   3]],\n",
       "  \n",
       "          [[ 28,  41,  47],\n",
       "           [ 30,  43,  50],\n",
       "           [ 32,  45,  52],\n",
       "           ...,\n",
       "           [  5,   6,   8],\n",
       "           [  4,   5,   3],\n",
       "           [  7,   8,   7]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[ 20,  15,  12],\n",
       "           [ 19,  14,  11],\n",
       "           [ 15,  14,  11],\n",
       "           ...,\n",
       "           [ 10,   9,   7],\n",
       "           [ 12,  11,   9],\n",
       "           [ 13,  12,  10]],\n",
       "  \n",
       "          [[ 21,  16,  13],\n",
       "           [ 20,  16,  13],\n",
       "           [ 18,  17,  12],\n",
       "           ...,\n",
       "           [ 10,   9,   7],\n",
       "           [ 10,   9,   7],\n",
       "           [ 12,  11,   9]],\n",
       "  \n",
       "          [[ 21,  16,  13],\n",
       "           [ 21,  17,  12],\n",
       "           [ 20,  18,  11],\n",
       "           ...,\n",
       "           [ 12,  11,   9],\n",
       "           [ 12,  11,   9],\n",
       "           [ 13,  12,  10]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 33,  25,  13],\n",
       "           [ 34,  26,  15],\n",
       "           [ 34,  26,  15],\n",
       "           ...,\n",
       "           [ 28,  25,  52],\n",
       "           [ 29,  25,  58],\n",
       "           [ 23,  20,  42]],\n",
       "  \n",
       "          [[ 33,  25,  14],\n",
       "           [ 34,  26,  15],\n",
       "           [ 34,  26,  15],\n",
       "           ...,\n",
       "           [ 27,  24,  52],\n",
       "           [ 27,  24,  56],\n",
       "           [ 25,  22,  47]],\n",
       "  \n",
       "          [[ 31,  23,  12],\n",
       "           [ 32,  24,  13],\n",
       "           [ 33,  25,  14],\n",
       "           ...,\n",
       "           [ 24,  23,  50],\n",
       "           [ 26,  23,  53],\n",
       "           [ 25,  20,  47]]],\n",
       "  \n",
       "  \n",
       "         [[[ 25,  40,  12],\n",
       "           [ 15,  36,   3],\n",
       "           [ 23,  41,  18],\n",
       "           ...,\n",
       "           [ 61,  82,  78],\n",
       "           [ 92, 113, 112],\n",
       "           [ 75,  89,  92]],\n",
       "  \n",
       "          [[ 12,  25,   6],\n",
       "           [ 20,  37,   7],\n",
       "           [ 24,  36,  15],\n",
       "           ...,\n",
       "           [115, 134, 138],\n",
       "           [149, 168, 177],\n",
       "           [104, 117, 131]],\n",
       "  \n",
       "          [[ 12,  25,  11],\n",
       "           [ 15,  29,   6],\n",
       "           [ 34,  40,  24],\n",
       "           ...,\n",
       "           [154, 172, 182],\n",
       "           [157, 175, 192],\n",
       "           [116, 129, 151]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[100, 129,  81],\n",
       "           [103, 132,  84],\n",
       "           [104, 134,  86],\n",
       "           ...,\n",
       "           [ 97, 128,  84],\n",
       "           [ 98, 126,  84],\n",
       "           [ 91, 121,  79]],\n",
       "  \n",
       "          [[103, 132,  83],\n",
       "           [104, 131,  83],\n",
       "           [107, 135,  87],\n",
       "           ...,\n",
       "           [101, 132,  87],\n",
       "           [ 99, 127,  84],\n",
       "           [ 92, 121,  79]],\n",
       "  \n",
       "          [[ 95, 126,  78],\n",
       "           [ 95, 123,  76],\n",
       "           [101, 128,  81],\n",
       "           ...,\n",
       "           [ 93, 124,  80],\n",
       "           [ 95, 123,  81],\n",
       "           [ 92, 120,  80]]],\n",
       "  \n",
       "  \n",
       "         [[[ 73,  78,  75],\n",
       "           [ 98, 103, 113],\n",
       "           [ 99, 106, 114],\n",
       "           ...,\n",
       "           [135, 150, 152],\n",
       "           [135, 149, 154],\n",
       "           [203, 215, 223]],\n",
       "  \n",
       "          [[ 69,  73,  70],\n",
       "           [ 84,  89,  97],\n",
       "           [ 68,  75,  81],\n",
       "           ...,\n",
       "           [ 85,  95,  89],\n",
       "           [ 71,  82,  80],\n",
       "           [120, 133, 135]],\n",
       "  \n",
       "          [[ 69,  73,  70],\n",
       "           [ 90,  95, 100],\n",
       "           [ 62,  71,  74],\n",
       "           ...,\n",
       "           [ 74,  81,  70],\n",
       "           [ 53,  62,  54],\n",
       "           [ 62,  74,  69]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[123, 128,  96],\n",
       "           [132, 132, 102],\n",
       "           [129, 128, 100],\n",
       "           ...,\n",
       "           [108, 107,  88],\n",
       "           [ 62,  60,  55],\n",
       "           [ 27,  27,  28]],\n",
       "  \n",
       "          [[115, 121,  91],\n",
       "           [123, 124,  95],\n",
       "           [129, 126,  99],\n",
       "           ...,\n",
       "           [115, 116,  94],\n",
       "           [ 66,  65,  59],\n",
       "           [ 27,  27,  27]],\n",
       "  \n",
       "          [[116, 120,  90],\n",
       "           [121, 122,  94],\n",
       "           [129, 128, 101],\n",
       "           ...,\n",
       "           [116, 115,  94],\n",
       "           [ 68,  65,  58],\n",
       "           [ 27,  26,  26]]]], dtype=uint8),\n",
       "  array([[3],\n",
       "         [8],\n",
       "         [8],\n",
       "         ...,\n",
       "         [5],\n",
       "         [1],\n",
       "         [7]])))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "x_train shape: (25000, 32, 32, 3)\n",
      "25000 train samples 25000 train labels\n",
      "5000 test samples 5000 test labels\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "data_augmentation = False #self generate additional training data\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train_all, y_train_all), (x_test_all, y_test_all) = cifar10.load_data()\n",
    "\n",
    "print(type(x_train_all))\n",
    "\n",
    "my_labels = [0,1,2,3,4]\n",
    "\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "temp = []\n",
    "for index in my_labels:\n",
    "    temp.append(label_names[index])\n",
    "label_names = index\n",
    "\n",
    "def label_name(num):\n",
    "    return label_names[num]\n",
    "    \n",
    "#temp lists\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "#filter training data\n",
    "for i in range(len(x_train_all)):\n",
    "    if y_train_all[i] in my_labels:\n",
    "        x_train.append(x_train_all[i])\n",
    "        y_train.append(y_train_all[i][0])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples', y_train.shape[0], 'train labels')\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "#filter test data\n",
    "for i in range(len(x_test_all)):\n",
    "    if y_test_all[i] in my_labels:\n",
    "        x_test.append(x_test_all[i])\n",
    "        y_test.append(y_test_all[i][0])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "print(x_test.shape[0], 'test samples', y_test.shape[0], 'test labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Train Classes and counts for each:\n",
      "[0 1 2 3 4] [5000 5000 5000 5000 5000]\n",
      "Unique Test Classes and counts for each:\n",
      "[0 1 2 3 4] [1000 1000 1000 1000 1000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Train Classes and counts for each:\")\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "print(unique, counts)\n",
    "\n",
    "print(\"Unique Test Classes and counts for each:\")\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "testindex = 4999\n",
    "img = x_test[testindex]\n",
    "plt.imshow(img)\n",
    "print(label_name(y_test[testindex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels to one hot vectors (for classification softmax loss)\n",
    "y_train = keras.utils.to_categorical(y_train, len(my_labels))\n",
    "y_test = keras.utils.to_categorical(y_test, len(my_labels))\n",
    "y_test[4999] #automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#values between 0 and 1 instead of 0 and 255\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#previous multidim. values => single vector 512\n",
    "#ohne flatten würde jeder filter einzeln interpretiert, so wird menge an filterergebnissen zusammengeführt\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(my_labels)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DatasetCardinality in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Train on 25000 samples, validate on 5000 samples\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op CreateSummaryFileWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteGraphSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlushSummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Epoch 1/50\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_distributed_function_1365 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignAddVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Equal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "   32/25000 [..............................] - ETA: 46:59 - loss: 1.6208 - accuracy: 0.1562Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "24704/25000 [============================>.] - ETA: 0s - loss: 1.2374 - accuracy: 0.4768Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op __inference_distributed_function_6988 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteScalarSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteScalarSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op WriteHistogramSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 9s 371us/sample - loss: 1.2347 - accuracy: 0.4781 - val_loss: 0.9875 - val_accuracy: 0.5934\n",
      "Epoch 2/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.9683 - accuracy: 0.6030Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 195us/sample - loss: 0.9683 - accuracy: 0.6030 - val_loss: 0.8723 - val_accuracy: 0.6456\n",
      "Epoch 3/50\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.8949 - accuracy: 0.6403Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 196us/sample - loss: 0.8946 - accuracy: 0.6406 - val_loss: 0.8344 - val_accuracy: 0.6780\n",
      "Epoch 4/50\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.8537 - accuracy: 0.6614Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 195us/sample - loss: 0.8531 - accuracy: 0.6615 - val_loss: 0.8085 - val_accuracy: 0.6866\n",
      "Epoch 5/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.8106 - accuracy: 0.6795Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 231us/sample - loss: 0.8099 - accuracy: 0.6798 - val_loss: 0.7573 - val_accuracy: 0.7092\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.7767 - accuracy: 0.6943Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 209us/sample - loss: 0.7763 - accuracy: 0.6944 - val_loss: 0.7468 - val_accuracy: 0.6984\n",
      "Epoch 7/50\n",
      "24960/25000 [============================>.] - ETA: 0s - loss: 0.7349 - accuracy: 0.7151Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 193us/sample - loss: 0.7347 - accuracy: 0.7152 - val_loss: 0.7044 - val_accuracy: 0.7280\n",
      "Epoch 8/50\n",
      "24928/25000 [============================>.] - ETA: 0s - loss: 0.7043 - accuracy: 0.7274Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 237us/sample - loss: 0.7042 - accuracy: 0.7274 - val_loss: 0.6639 - val_accuracy: 0.7424\n",
      "Epoch 9/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.7415Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 200us/sample - loss: 0.6771 - accuracy: 0.7415 - val_loss: 0.6549 - val_accuracy: 0.7424\n",
      "Epoch 10/50\n",
      "24928/25000 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.7490Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 258us/sample - loss: 0.6515 - accuracy: 0.7489 - val_loss: 0.6219 - val_accuracy: 0.7658\n",
      "Epoch 11/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.6255 - accuracy: 0.7635Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 219us/sample - loss: 0.6259 - accuracy: 0.7634 - val_loss: 0.6202 - val_accuracy: 0.7584\n",
      "Epoch 12/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.6050 - accuracy: 0.7689Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 223us/sample - loss: 0.6047 - accuracy: 0.7691 - val_loss: 0.5984 - val_accuracy: 0.7760\n",
      "Epoch 13/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.7805Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.5797 - accuracy: 0.7809 - val_loss: 0.5734 - val_accuracy: 0.7814\n",
      "Epoch 14/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.5635 - accuracy: 0.7854Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.5637 - accuracy: 0.7854 - val_loss: 0.5585 - val_accuracy: 0.7874\n",
      "Epoch 15/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.7941Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 238us/sample - loss: 0.5445 - accuracy: 0.7943 - val_loss: 0.5491 - val_accuracy: 0.7898\n",
      "Epoch 16/50\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8011Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 200us/sample - loss: 0.5247 - accuracy: 0.8014 - val_loss: 0.5715 - val_accuracy: 0.7868\n",
      "Epoch 17/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.5072 - accuracy: 0.8098Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 10s 408us/sample - loss: 0.5075 - accuracy: 0.8098 - val_loss: 0.5448 - val_accuracy: 0.7948\n",
      "Epoch 18/50\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.8131Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 196us/sample - loss: 0.4928 - accuracy: 0.8132 - val_loss: 0.5367 - val_accuracy: 0.8010\n",
      "Epoch 19/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.8220Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 201us/sample - loss: 0.4762 - accuracy: 0.8220 - val_loss: 0.5253 - val_accuracy: 0.8022\n",
      "Epoch 20/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8265Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 220us/sample - loss: 0.4623 - accuracy: 0.8266 - val_loss: 0.5111 - val_accuracy: 0.8096\n",
      "Epoch 21/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8323Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 215us/sample - loss: 0.4466 - accuracy: 0.8323 - val_loss: 0.5128 - val_accuracy: 0.8068\n",
      "Epoch 22/50\n",
      "24736/25000 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8376Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 225us/sample - loss: 0.4359 - accuracy: 0.8375 - val_loss: 0.5001 - val_accuracy: 0.8152\n",
      "Epoch 23/50\n",
      "24832/25000 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8431Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 198us/sample - loss: 0.4190 - accuracy: 0.8428 - val_loss: 0.5126 - val_accuracy: 0.8148\n",
      "Epoch 24/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.4128 - accuracy: 0.8465Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 226us/sample - loss: 0.4126 - accuracy: 0.8465 - val_loss: 0.5094 - val_accuracy: 0.8122\n",
      "Epoch 25/50\n",
      "24960/25000 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8528Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 239us/sample - loss: 0.3946 - accuracy: 0.8529 - val_loss: 0.4878 - val_accuracy: 0.8180\n",
      "Epoch 26/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8588Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 230us/sample - loss: 0.3830 - accuracy: 0.8589 - val_loss: 0.4885 - val_accuracy: 0.8198\n",
      "Epoch 27/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.8604Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 229us/sample - loss: 0.3720 - accuracy: 0.8602 - val_loss: 0.4840 - val_accuracy: 0.8238\n",
      "Epoch 28/50\n",
      "24960/25000 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.8679Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 6s 228us/sample - loss: 0.3573 - accuracy: 0.8679 - val_loss: 0.4809 - val_accuracy: 0.8250\n",
      "Epoch 29/50\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.3498 - accuracy: 0.8685Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 210us/sample - loss: 0.3496 - accuracy: 0.8685 - val_loss: 0.4912 - val_accuracy: 0.8214\n",
      "Epoch 30/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.8774Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 204us/sample - loss: 0.3327 - accuracy: 0.8774 - val_loss: 0.4816 - val_accuracy: 0.8250\n",
      "Epoch 31/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8788Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 194us/sample - loss: 0.3258 - accuracy: 0.8787 - val_loss: 0.4799 - val_accuracy: 0.8236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.3158 - accuracy: 0.8831Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 197us/sample - loss: 0.3159 - accuracy: 0.8831 - val_loss: 0.4874 - val_accuracy: 0.8276\n",
      "Epoch 33/50\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.8877Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 183us/sample - loss: 0.3048 - accuracy: 0.8878 - val_loss: 0.4718 - val_accuracy: 0.8322\n",
      "Epoch 34/50\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8918Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 186us/sample - loss: 0.2959 - accuracy: 0.8916 - val_loss: 0.4809 - val_accuracy: 0.8246\n",
      "Epoch 35/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.8951Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 182us/sample - loss: 0.2860 - accuracy: 0.8951 - val_loss: 0.4783 - val_accuracy: 0.8290\n",
      "Epoch 36/50\n",
      "24960/25000 [============================>.] - ETA: 0s - loss: 0.2829 - accuracy: 0.8952Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 188us/sample - loss: 0.2832 - accuracy: 0.8951 - val_loss: 0.4791 - val_accuracy: 0.8304\n",
      "Epoch 37/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9020Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 193us/sample - loss: 0.2682 - accuracy: 0.9020 - val_loss: 0.4758 - val_accuracy: 0.8344\n",
      "Epoch 38/50\n",
      "24800/25000 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9039Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 197us/sample - loss: 0.2625 - accuracy: 0.9041 - val_loss: 0.4811 - val_accuracy: 0.8342\n",
      "Epoch 39/50\n",
      "24896/25000 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9082Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 213us/sample - loss: 0.2508 - accuracy: 0.9082 - val_loss: 0.4864 - val_accuracy: 0.8334\n",
      "Epoch 40/50\n",
      "24864/25000 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9102Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 185us/sample - loss: 0.2389 - accuracy: 0.9101 - val_loss: 0.4930 - val_accuracy: 0.8304\n",
      "Epoch 41/50\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9116Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 199us/sample - loss: 0.2364 - accuracy: 0.9116 - val_loss: 0.4758 - val_accuracy: 0.8390\n",
      "Epoch 42/50\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9178Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 195us/sample - loss: 0.2224 - accuracy: 0.9181 - val_loss: 0.4947 - val_accuracy: 0.8358\n",
      "Epoch 43/50\n",
      "24768/25000 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9199Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "25000/25000 [==============================] - 5s 184us/sample - loss: 0.2175 - accuracy: 0.9199 - val_loss: 0.5063 - val_accuracy: 0.8326\n",
      "Epoch 44/50\n",
      "24544/25000 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9210Executing op CloseSummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-39d879da7503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m           callbacks=[tensorboard_callback])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "# open tb: tensorboard --logdir logs/\n",
    "logdir = os.path.join(os.getcwd(), 'logs\\\\'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at S:\\Hub\\ML_SS_2020\\saved_models\\keras_cifar10_trained_model.h5 \n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "5000/5000 [==============================] - 0s 84us/sample - loss: 0.5385 - accuracy: 0.7988\n",
      "Test loss: 0.5384670739173889\n",
      "Test accuracy: 0.7988\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
