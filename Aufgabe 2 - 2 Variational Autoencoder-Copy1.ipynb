{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#must be very first statement\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#utils'\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.datasets import mnist\n",
    "import PIL\n",
    "\n",
    "\n",
    "def getDigits(show=False):\n",
    "    (x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
    "\n",
    "    #print(x_train.shape)\n",
    "\n",
    "    if show:\n",
    "        showImages(x_train, t_train,5)\n",
    "\n",
    "    return x_train,t_train,x_test, t_test\n",
    "\n",
    "\n",
    "#### CALLBACKS (https://github.com/davidADSP/GDL_code/blob/master/utils/callbacks.py)\n",
    "class CustomCallback(Callback):\n",
    "\n",
    "    def __init__(self, run_folder, print_every_n_batches, initial_epoch, vae):\n",
    "        self.epoch = initial_epoch\n",
    "        self.run_folder = run_folder\n",
    "        self.print_every_n_batches = print_every_n_batches\n",
    "        self.vae = vae\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if batch % self.print_every_n_batches == 0:\n",
    "            z_new = np.random.normal(size=(1, self.vae.z_dim))\n",
    "            reconst = self.vae.decoder.predict(np.array(z_new))[0].squeeze()\n",
    "\n",
    "            filepath = os.path.join(self.run_folder, 'images',\n",
    "                                    'img_' + str(self.epoch).zfill(3) + '_' + str(batch) + '.jpg')\n",
    "            if len(reconst.shape) == 2:\n",
    "                plt.imsave(filepath, reconst, cmap='gray_r')\n",
    "            else:\n",
    "                plt.imsave(filepath, reconst)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch += 1\n",
    "\n",
    "#### CALLBACKS (https://github.com/davidADSP/GDL_code/blob/master/utils/callbacks.py)\n",
    "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "\n",
    "    def schedule(epoch):\n",
    "        new_lr = initial_lr * (decay_factor ** np.floor(epoch / step_size))\n",
    "\n",
    "        return new_lr\n",
    "\n",
    "    return LearningRateScheduler(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining new Labeling:\n",
      "{0: 'bird'}\n",
      "Training Data:\n",
      "\n",
      "x_train shape: (5000, 32, 32, 3)\n",
      "5000 samples, 5000 labels\n",
      "\n",
      "Class  |  Counts:\n",
      "bird \t 5000\n",
      "\n",
      "\n",
      "Testing Data:\n",
      "\n",
      "x_test shape: (1000, 32, 32, 3)\n",
      "1000 samples, 1000 labels\n",
      "\n",
      "Class  |  Counts:\n",
      "bird \t 1000\n"
     ]
    }
   ],
   "source": [
    "#data prep\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "cifar10.load_data()\n",
    "\n",
    "my_labels = [2]\n",
    "all_label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "label_names = []\n",
    "for label_index in my_labels:\n",
    "    label_names.append(all_label_names[label_index])  \n",
    "\n",
    "print(\"Defining new Labeling:\")\n",
    "print(dict(zip(range(len(my_labels)),label_names)))\n",
    "\n",
    "#if my_labels = [5,6,8] then 5 returns 0, 6 returns 1, 8 returns 2, ...\n",
    "def convert_label(label):\n",
    "    return dict(zip(my_labels,range(len(my_labels))))[label]\n",
    "\n",
    "def label_name(num):\n",
    "    return label_names[num]\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train_all, y_train_all), (x_test_all, y_test_all) = cifar10.load_data()\n",
    "    \n",
    "#temp lists\n",
    "x_train = []\n",
    "y_train_numerical = []\n",
    "\n",
    "#filter training data for my_labels\n",
    "for i in range(len(x_train_all)):\n",
    "    if y_train_all[i] in my_labels:\n",
    "        x_train.append(x_train_all[i])\n",
    "        y_train_numerical.append(convert_label(y_train_all[i][0]))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train_numerical = np.array(y_train_numerical)\n",
    "\n",
    "print(\"Training Data:\\n\")\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'samples,', y_train_numerical.shape[0], 'labels')\n",
    "print(\"\\nClass  |  Counts:\")\n",
    "(unique, counts) = np.unique(y_train_numerical, return_counts=True)\n",
    "for i, label in enumerate(unique):\n",
    "    print(label_name(label),\"\\t\", counts[i])\n",
    "\n",
    "\n",
    "x_test = []\n",
    "y_test_numerical = []\n",
    "\n",
    "#filter test data\n",
    "for i in range(len(x_test_all)):\n",
    "    if y_test_all[i] in my_labels:\n",
    "        x_test.append(x_test_all[i])\n",
    "        y_test_numerical.append(convert_label(y_test_all[i][0]))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test_numerical = np.array(y_test_numerical)\n",
    "\n",
    "print(\"\\n\\nTesting Data:\\n\")\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_test.shape[0], 'samples,', y_test_numerical.shape[0], 'labels')\n",
    "print(\"\\nClass  |  Counts:\")\n",
    "(unique, counts) = np.unique(y_test_numerical, return_counts=True)\n",
    "for i, label in enumerate(unique):\n",
    "    print(label_name(label),\"\\t\", counts[i])\n",
    "    \n",
    "x_train=x_train.reshape(x_train.shape[0],32,32,3)\n",
    "x_test=x_test.reshape(x_test.shape[0],32,32,3)\n",
    "\n",
    "x_train = x_train.astype('float32')[:1000]\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class\n",
    "\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras import callbacks\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "class VariationalAutoencoder():\n",
    "    def __init__(self\n",
    "                 , input_dim\n",
    "                 , encoder_conv_filters\n",
    "                 , encoder_conv_kernel_size\n",
    "                 , encoder_conv_strides\n",
    "                 , decoder_conv_t_filters\n",
    "                 , decoder_conv_t_kernel_size\n",
    "                 , decoder_conv_t_strides\n",
    "                 , z_dim\n",
    "                 , use_batch_norm=False\n",
    "                 , use_dropout=False\n",
    "                 ):\n",
    "\n",
    "        self.name = 'variational_autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "\n",
    "        ### THE ENCODER\n",
    "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
    "\n",
    "        x = encoder_input\n",
    "\n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_layer = Conv2D(\n",
    "                filters=self.encoder_conv_filters[i]\n",
    "                , kernel_size=self.encoder_conv_kernel_size[i]\n",
    "                , strides=self.encoder_conv_strides[i]\n",
    "                , padding='same'\n",
    "                , name='encoder_conv_' + str(i)\n",
    "            )\n",
    "\n",
    "            x = conv_layer(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate=0.25)(x)\n",
    "\n",
    "        shape_before_flattening = K.int_shape(x)[1:]\n",
    "#-----------------------------\n",
    "        print(\"shape_bef_flat\",shape_before_flattening)\n",
    "        x = Flatten()(x)\n",
    "        print(\"shape_aft_flat\",x)\n",
    "        self.mu = Dense(self.z_dim, name='mu')(x)\n",
    "        self.log_var = Dense(self.z_dim, name='log_var')(x)\n",
    "\n",
    "        self.encoder_mu_log_var = Model(encoder_input, (self.mu, self.log_var))\n",
    "\n",
    "        def sampling(args):\n",
    "            mu, log_var = args\n",
    "            epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1)\n",
    "            return mu + K.exp(log_var / 2) * epsilon #try without /2\n",
    "    \n",
    "        encoder_output = Lambda(sampling, name='encoder_output')([self.mu, self.log_var])\n",
    "        print(\"encoder_output: \",encoder_output)\n",
    "        self.encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "        ### THE DECODER\n",
    "\n",
    "        decoder_input = Input(shape=(self.z_dim,), name='decoder_input')\n",
    "        print(\"dec_input\",decoder_input)\n",
    "        x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "        x = Reshape(shape_before_flattening)(x)\n",
    "\n",
    "        for i in range(self.n_layers_decoder):\n",
    "            conv_t_layer = Conv2DTranspose(\n",
    "                filters=self.decoder_conv_t_filters[i]\n",
    "                , kernel_size=self.decoder_conv_t_kernel_size[i]\n",
    "                , strides=self.decoder_conv_t_strides[i]\n",
    "                , padding='same'\n",
    "                , name='decoder_conv_t_' + str(i)\n",
    "            )\n",
    "\n",
    "            x = conv_t_layer(x)\n",
    "\n",
    "            if i < self.n_layers_decoder - 1:\n",
    "                if self.use_batch_norm:\n",
    "                    x = BatchNormalization()(x)\n",
    "                x = LeakyReLU()(x)\n",
    "                if self.use_dropout:\n",
    "                    x = Dropout(rate=0.25)(x)\n",
    "            else:\n",
    "                x = Activation('sigmoid')(x)\n",
    "\n",
    "        decoder_output = x\n",
    "        print(\"dec_inputtii\",decoder_input)\n",
    "        self.decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "        ### THE FULL VAE\n",
    "        model_input = encoder_input\n",
    "        model_output = self.decoder(encoder_output)\n",
    "        \n",
    "        self.model = Model(model_input, model_output)\n",
    "\n",
    "    def compile(self, learning_rate, r_loss_factor):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        ### COMPILATION\n",
    "        def vae_r_loss(y_true, y_pred):\n",
    "            r_loss = K.mean(K.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "            return r_loss * r_loss_factor\n",
    "\n",
    "        def vae_kl_loss(y_true, y_pred):\n",
    "            kl_loss = -0.5 * K.sum(1 + self.log_var - K.square(self.mu) - K.exp(self.log_var), axis=1)\n",
    "            return kl_loss\n",
    "\n",
    "        def vae_loss(y_true, y_pred):\n",
    "\n",
    "            #return 0.99*vae_r_loss(y_true,y_pred)+0.01*vae_kl_loss(y_true,y_pred)\n",
    "            r_loss = vae_r_loss(y_true, y_pred)\n",
    "            kl_loss = vae_kl_loss(y_true, y_pred)\n",
    "            return r_loss + kl_loss\n",
    "\n",
    "        optimizer = Adam(lr=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss=vae_loss, metrics=[vae_r_loss, vae_kl_loss])\n",
    "\n",
    "    def save(self, folder=\"run\"):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            os.makedirs(os.path.join(folder, 'viz'))\n",
    "            os.makedirs(os.path.join(folder, 'weights'))\n",
    "            os.makedirs(os.path.join(folder, 'images'))\n",
    "\n",
    "        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n",
    "            pickle.dump([\n",
    "                self.input_dim\n",
    "                , self.encoder_conv_filters\n",
    "                , self.encoder_conv_kernel_size\n",
    "                , self.encoder_conv_strides\n",
    "                , self.decoder_conv_t_filters\n",
    "                , self.decoder_conv_t_kernel_size\n",
    "                , self.decoder_conv_t_strides\n",
    "                , self.z_dim\n",
    "                , self.use_batch_norm\n",
    "                , self.use_dropout\n",
    "            ], f)\n",
    "\n",
    "        self.plot_model(folder)\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        self.model.load_weights(filepath)\n",
    "\n",
    "    def train(self, x_train, batch_size, epochs, run_folder, print_every_n_batches=100, initial_epoch=0, lr_decay=1):\n",
    "\n",
    "        custom_callback = CustomCallback(run_folder, print_every_n_batches, initial_epoch, self)\n",
    "        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\n",
    "\n",
    "        checkpoint_filepath = os.path.join(run_folder, \"weights/weights.h5\")\n",
    "        \n",
    "        model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_acc',\n",
    "            mode='max')\n",
    "\n",
    "        \n",
    "        #checkpoint1 = ModelCheckpoint(checkpoint_filepath, save_weights_only=True, verbose=1)\n",
    "        #checkpoint2 = ModelCheckpoint(os.path.join(run_folder, 'weights/weights.h5'), save_weights_only=True, verbose=1)\n",
    "\n",
    "        callbacks_list = [custom_callback, lr_sched, model_checkpoint_callback]\n",
    "\n",
    "        self.model.fit(\n",
    "            x_train\n",
    "            , x_train\n",
    "            , batch_size=batch_size\n",
    "            , shuffle=True\n",
    "            , epochs=epochs\n",
    "            , initial_epoch=initial_epoch\n",
    "            , callbacks=callbacks_list\n",
    "        )\n",
    "\n",
    "    def plot_model(self, run_folder):\n",
    "        plot_model(self.model, to_file=os.path.join(run_folder, 'viz/model.png'), show_shapes=True,\n",
    "                   show_layer_names=True)\n",
    "        plot_model(self.encoder, to_file=os.path.join(run_folder, 'viz/encoder.png'), show_shapes=True,\n",
    "                   show_layer_names=True)\n",
    "        plot_model(self.decoder, to_file=os.path.join(run_folder, 'viz/decoder.png'), show_shapes=True,\n",
    "                   show_layer_names=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:\\Hub\\ML_SS_2020\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'digits'\n",
    "RUN_FOLDER = 'run'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vae = VariationalAutoencoder(\n",
    "    input_dim = (32,32,3)\n",
    "    , encoder_conv_filters = [128,128,128,512]\n",
    "    , encoder_conv_kernel_size = [2,2,3,4]\n",
    "    , encoder_conv_strides = [1,1,2,2]\n",
    "    , decoder_conv_t_filters = [512,128,128,3]\n",
    "    , decoder_conv_t_kernel_size = [4,3,2,2]\n",
    "    , decoder_conv_t_strides = [2,2,1,1]\n",
    "    , z_dim = 128\n",
    ")\n",
    "vae.save(RUN_FOLDER)\n",
    "\n",
    "vae.load_weights(\"run/weights/weights.h5\")\n",
    "\n",
    "vae.encoder.summary()\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "R_LOSS_FACTOR = 1000\n",
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "\n",
    "vae.train(\n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")\n",
    "vae.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Epoch 1/1000\n",
      "Executing op __inference_keras_scratch_graph_256224 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 22.9052 - vae_r_loss: 12.8706 - vae_kl_loss: 10.0347\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.2420 - vae_r_loss: 10.3650 - vae_kl_loss: 9.8770\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0193 - vae_r_loss: 10.1976 - vae_kl_loss: 9.8217\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1019 - vae_r_loss: 10.2670 - vae_kl_loss: 9.8349\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1155 - vae_r_loss: 10.3163 - vae_kl_loss: 9.7992\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1279 - vae_r_loss: 10.2025 - vae_kl_loss: 9.9254\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0434 - vae_r_loss: 10.2868 - vae_kl_loss: 9.7566\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9118 - vae_r_loss: 10.1168 - vae_kl_loss: 9.7950\n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0047 - vae_r_loss: 10.1167 - vae_kl_loss: 9.8880\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9941 - vae_r_loss: 10.2185 - vae_kl_loss: 9.7757\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0275 - vae_r_loss: 10.1188 - vae_kl_loss: 9.9088\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9337 - vae_r_loss: 10.1669 - vae_kl_loss: 9.7668\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.3926 - vae_r_loss: 10.4600 - vae_kl_loss: 9.9326\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1762 - vae_r_loss: 10.2370 - vae_kl_loss: 9.9392\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9158 - vae_r_loss: 10.1266 - vae_kl_loss: 9.7893: 0s - loss: 19.7603 - vae_r_loss: 1\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0970 - vae_r_loss: 10.2291 - vae_kl_loss: 9.8679\n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0718 - vae_r_loss: 10.2776 - vae_kl_loss: 9.7942\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1536 - vae_r_loss: 10.3068 - vae_kl_loss: 9.8467\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9647 - vae_r_loss: 10.0992 - vae_kl_loss: 9.8655\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0154 - vae_r_loss: 10.1740 - vae_kl_loss: 9.8415\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1119 - vae_r_loss: 10.2298 - vae_kl_loss: 9.8821\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9445 - vae_r_loss: 10.1065 - vae_kl_loss: 9.8380\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.3754 - vae_r_loss: 10.3253 - vae_kl_loss: 10.0501\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1698 - vae_r_loss: 10.2248 - vae_kl_loss: 9.9449\n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0796 - vae_r_loss: 10.2042 - vae_kl_loss: 9.8755\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0832 - vae_r_loss: 10.2722 - vae_kl_loss: 9.8110\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9942 - vae_r_loss: 10.1337 - vae_kl_loss: 9.8606\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7801 - vae_r_loss: 10.1268 - vae_kl_loss: 9.6532\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8302 - vae_r_loss: 10.0118 - vae_kl_loss: 9.8184\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0718 - vae_r_loss: 10.0092 - vae_kl_loss: 10.0626\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9757 - vae_r_loss: 10.0952 - vae_kl_loss: 9.8805\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6756 - vae_r_loss: 10.0030 - vae_kl_loss: 9.6726\n",
      "Epoch 33/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9574 - vae_r_loss: 10.0677 - vae_kl_loss: 9.8897\n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1711 - vae_r_loss: 10.3495 - vae_kl_loss: 9.8216\n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1178 - vae_r_loss: 10.1777 - vae_kl_loss: 9.9400\n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0607 - vae_r_loss: 10.2168 - vae_kl_loss: 9.8439\n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.2614 - vae_r_loss: 10.3699 - vae_kl_loss: 9.8915\n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0241 - vae_r_loss: 10.0520 - vae_kl_loss: 9.9721\n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1791 - vae_r_loss: 10.0800 - vae_kl_loss: 10.0992\n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0013 - vae_r_loss: 10.1501 - vae_kl_loss: 9.8512\n",
      "Epoch 41/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7994 - vae_r_loss: 9.9550 - vae_kl_loss: 9.8444\n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0896 - vae_r_loss: 10.2356 - vae_kl_loss: 9.8539\n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9478 - vae_r_loss: 10.0771 - vae_kl_loss: 9.8708\n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9624 - vae_r_loss: 10.1042 - vae_kl_loss: 9.8581\n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1560 - vae_r_loss: 10.2802 - vae_kl_loss: 9.8757\n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1682 - vae_r_loss: 10.2527 - vae_kl_loss: 9.9154\n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1030 - vae_r_loss: 10.1482 - vae_kl_loss: 9.9548\n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9926 - vae_r_loss: 10.0996 - vae_kl_loss: 9.8931\n",
      "Epoch 49/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1605 - vae_r_loss: 10.0736 - vae_kl_loss: 10.0869\n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8379 - vae_r_loss: 9.9633 - vae_kl_loss: 9.8746\n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9032 - vae_r_loss: 9.9501 - vae_kl_loss: 9.9531\n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9810 - vae_r_loss: 10.0702 - vae_kl_loss: 9.9108\n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0363 - vae_r_loss: 9.9841 - vae_kl_loss: 10.0522\n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9543 - vae_r_loss: 10.1526 - vae_kl_loss: 9.8017\n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.2241 - vae_r_loss: 10.1259 - vae_kl_loss: 10.0982\n",
      "Epoch 56/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0591 - vae_r_loss: 10.1281 - vae_kl_loss: 9.9310\n",
      "Epoch 57/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0936 - vae_r_loss: 10.0719 - vae_kl_loss: 10.0217\n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9200 - vae_r_loss: 10.0884 - vae_kl_loss: 9.8316\n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9555 - vae_r_loss: 9.9460 - vae_kl_loss: 10.0095\n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8622 - vae_r_loss: 10.0342 - vae_kl_loss: 9.8280\n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8175 - vae_r_loss: 10.0169 - vae_kl_loss: 9.8006\n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0357 - vae_r_loss: 10.0763 - vae_kl_loss: 9.9594\n",
      "Epoch 63/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8396 - vae_r_loss: 9.9660 - vae_kl_loss: 9.8736\n",
      "Epoch 64/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0523 - vae_r_loss: 10.1838 - vae_kl_loss: 9.8684\n",
      "Epoch 65/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8175 - vae_r_loss: 10.0132 - vae_kl_loss: 9.8043\n",
      "Epoch 66/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0243 - vae_r_loss: 9.9676 - vae_kl_loss: 10.0566\n",
      "Epoch 67/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0432 - vae_r_loss: 10.0295 - vae_kl_loss: 10.0137\n",
      "Epoch 68/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1852 - vae_r_loss: 10.1959 - vae_kl_loss: 9.9893\n",
      "Epoch 69/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8818 - vae_r_loss: 9.9638 - vae_kl_loss: 9.9180\n",
      "Epoch 70/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9383 - vae_r_loss: 10.0221 - vae_kl_loss: 9.9163\n",
      "Epoch 71/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9229 - vae_r_loss: 10.0297 - vae_kl_loss: 9.8932\n",
      "Epoch 72/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9291 - vae_r_loss: 10.0694 - vae_kl_loss: 9.8597\n",
      "Epoch 73/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8889 - vae_r_loss: 10.1185 - vae_kl_loss: 9.7704\n",
      "Epoch 74/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8093 - vae_r_loss: 9.8199 - vae_kl_loss: 9.9893\n",
      "Epoch 75/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9617 - vae_r_loss: 10.0718 - vae_kl_loss: 9.8900\n",
      "Epoch 76/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0152 - vae_r_loss: 10.0142 - vae_kl_loss: 10.0010\n",
      "Epoch 77/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8715 - vae_r_loss: 9.9176 - vae_kl_loss: 9.9539\n",
      "Epoch 78/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8164 - vae_r_loss: 9.9066 - vae_kl_loss: 9.9099\n",
      "Epoch 79/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6749 - vae_r_loss: 9.8061 - vae_kl_loss: 9.8688\n",
      "Epoch 80/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7581 - vae_r_loss: 9.8709 - vae_kl_loss: 9.8873A: 0s - loss: 19.8020 - vae_r_loss: 9.9222 - vae_kl_loss: 9. - ETA: 0s - loss: 19.7459 - vae_r_loss: 9.8482 - vae_kl_loss: \n",
      "Epoch 81/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7881 - vae_r_loss: 9.9072 - vae_kl_loss: 9.8809A: 1s - loss: 19.8340 - vae_r_loss: 10.1153 \n",
      "Epoch 82/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8649 - vae_r_loss: 9.9343 - vae_kl_loss: 9.9306A: 1s - loss: 19.8213 - vae_r\n",
      "Epoch 83/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9709 - vae_r_loss: 10.0865 - vae_kl_loss: 9.8844\n",
      "Epoch 84/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1662 - vae_r_loss: 10.0363 - vae_kl_loss: 10.1299\n",
      "Epoch 85/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9283 - vae_r_loss: 9.8951 - vae_kl_loss: 10.0332\n",
      "Epoch 86/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7693 - vae_r_loss: 9.7991 - vae_kl_loss: 9.9702\n",
      "Epoch 87/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8993 - vae_r_loss: 9.7807 - vae_kl_loss: 10.1186\n",
      "Epoch 88/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8512 - vae_r_loss: 9.9640 - vae_kl_loss: 9.8872\n",
      "Epoch 89/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9866 - vae_r_loss: 10.0024 - vae_kl_loss: 9.9842\n",
      "Epoch 90/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1033 - vae_r_loss: 10.0977 - vae_kl_loss: 10.0056\n",
      "Epoch 91/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9594 - vae_r_loss: 9.9369 - vae_kl_loss: 10.0225\n",
      "Epoch 92/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7758 - vae_r_loss: 9.9350 - vae_kl_loss: 9.8408\n",
      "Epoch 93/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0666 - vae_r_loss: 10.0047 - vae_kl_loss: 10.0619\n",
      "Epoch 94/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0687 - vae_r_loss: 10.0461 - vae_kl_loss: 10.0226\n",
      "Epoch 95/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0332 - vae_r_loss: 9.9030 - vae_kl_loss: 10.1301\n",
      "Epoch 96/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9181 - vae_r_loss: 9.8619 - vae_kl_loss: 10.0562\n",
      "Epoch 97/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9080 - vae_r_loss: 9.9568 - vae_kl_loss: 9.9512\n",
      "Epoch 98/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7365 - vae_r_loss: 9.8332 - vae_kl_loss: 9.9032\n",
      "Epoch 99/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8510 - vae_r_loss: 9.8978 - vae_kl_loss: 9.9532\n",
      "Epoch 100/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8496 - vae_r_loss: 9.9032 - vae_kl_loss: 9.9464\n",
      "Epoch 101/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8470 - vae_r_loss: 9.8743 - vae_kl_loss: 9.9727\n",
      "Epoch 102/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7270 - vae_r_loss: 9.8125 - vae_kl_loss: 9.9145\n",
      "Epoch 103/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0598 - vae_r_loss: 10.0049 - vae_kl_loss: 10.0549\n",
      "Epoch 104/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9301 - vae_r_loss: 9.9181 - vae_kl_loss: 10.0120\n",
      "Epoch 105/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9553 - vae_r_loss: 10.0328 - vae_kl_loss: 9.9225\n",
      "Epoch 106/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7637 - vae_r_loss: 9.7745 - vae_kl_loss: 9.9892\n",
      "Epoch 107/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.4725 - vae_r_loss: 10.2919 - vae_kl_loss: 10.1806\n",
      "Epoch 108/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9806 - vae_r_loss: 9.8948 - vae_kl_loss: 10.0857\n",
      "Epoch 109/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7698 - vae_r_loss: 9.8234 - vae_kl_loss: 9.9464\n",
      "Epoch 110/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6685 - vae_r_loss: 9.6505 - vae_kl_loss: 10.0180\n",
      "Epoch 111/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8479 - vae_r_loss: 10.0328 - vae_kl_loss: 9.8151: 1s - loss: 19.9864 - vae_r_\n",
      "Epoch 112/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8866 - vae_r_loss: 9.8453 - vae_kl_loss: 10.0413\n",
      "Epoch 113/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6944 - vae_r_loss: 9.8704 - vae_kl_loss: 9.8239\n",
      "Epoch 114/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8717 - vae_r_loss: 9.8224 - vae_kl_loss: 10.0493\n",
      "Epoch 115/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6396 - vae_r_loss: 9.7851 - vae_kl_loss: 9.8545\n",
      "Epoch 116/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9199 - vae_r_loss: 9.9208 - vae_kl_loss: 9.9991\n",
      "Epoch 117/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9679 - vae_r_loss: 9.8915 - vae_kl_loss: 10.0764\n",
      "Epoch 118/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6905 - vae_r_loss: 9.7677 - vae_kl_loss: 9.9228\n",
      "Epoch 119/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1263 - vae_r_loss: 10.2688 - vae_kl_loss: 9.8575\n",
      "Epoch 120/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7880 - vae_r_loss: 9.7869 - vae_kl_loss: 10.0010\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9933 - vae_r_loss: 10.0314 - vae_kl_loss: 9.9619\n",
      "Epoch 122/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8449 - vae_r_loss: 9.8305 - vae_kl_loss: 10.0144: 0s - loss: 19.9383 - vae_r_loss: 9.8460 - \n",
      "Epoch 123/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7438 - vae_r_loss: 9.8116 - vae_kl_loss: 9.9322\n",
      "Epoch 124/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7634 - vae_r_loss: 9.6747 - vae_kl_loss: 10.0887\n",
      "Epoch 125/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0526 - vae_r_loss: 10.0711 - vae_kl_loss: 9.9814\n",
      "Epoch 126/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8735 - vae_r_loss: 9.7704 - vae_kl_loss: 10.1031\n",
      "Epoch 127/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6878 - vae_r_loss: 9.7322 - vae_kl_loss: 9.9556\n",
      "Epoch 128/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4828 - vae_r_loss: 9.6355 - vae_kl_loss: 9.8473\n",
      "Epoch 129/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8028 - vae_r_loss: 9.8617 - vae_kl_loss: 9.9411\n",
      "Epoch 130/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6122 - vae_r_loss: 9.6086 - vae_kl_loss: 10.0037\n",
      "Epoch 131/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7201 - vae_r_loss: 9.7716 - vae_kl_loss: 9.9485A: 0s - loss: 19.6886 - vae_r_loss: 9.7112 - vae_kl_loss: 9\n",
      "Epoch 132/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6751 - vae_r_loss: 9.7477 - vae_kl_loss: 9.9274\n",
      "Epoch 133/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7754 - vae_r_loss: 9.9336 - vae_kl_loss: 9.8418\n",
      "Epoch 134/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.1075 - vae_r_loss: 10.0315 - vae_kl_loss: 10.0759\n",
      "Epoch 135/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6833 - vae_r_loss: 9.7038 - vae_kl_loss: 9.9795\n",
      "Epoch 136/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6957 - vae_r_loss: 9.7666 - vae_kl_loss: 9.9291\n",
      "Epoch 137/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7356 - vae_r_loss: 9.7633 - vae_kl_loss: 9.9723\n",
      "Epoch 138/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6837 - vae_r_loss: 9.7706 - vae_kl_loss: 9.9131A: 0s - loss: 19.6121 - vae_r_loss: 9.6867 - vae_kl_lo\n",
      "Epoch 139/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5909 - vae_r_loss: 9.5979 - vae_kl_loss: 9.9930\n",
      "Epoch 140/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6370 - vae_r_loss: 9.6217 - vae_kl_loss: 10.0153\n",
      "Epoch 141/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7621 - vae_r_loss: 9.7594 - vae_kl_loss: 10.0027\n",
      "Epoch 142/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7647 - vae_r_loss: 9.7275 - vae_kl_loss: 10.0372\n",
      "Epoch 143/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6309 - vae_r_loss: 9.6221 - vae_kl_loss: 10.0088\n",
      "Epoch 144/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5746 - vae_r_loss: 9.6751 - vae_kl_loss: 9.8995\n",
      "Epoch 145/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5880 - vae_r_loss: 9.6039 - vae_kl_loss: 9.9841\n",
      "Epoch 146/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7503 - vae_r_loss: 9.6735 - vae_kl_loss: 10.0768\n",
      "Epoch 147/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6468 - vae_r_loss: 9.8605 - vae_kl_loss: 9.7862\n",
      "Epoch 148/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8723 - vae_r_loss: 9.8391 - vae_kl_loss: 10.0332\n",
      "Epoch 149/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8127 - vae_r_loss: 9.8824 - vae_kl_loss: 9.9302\n",
      "Epoch 150/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6861 - vae_r_loss: 9.6533 - vae_kl_loss: 10.0327\n",
      "Epoch 151/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7333 - vae_r_loss: 9.7137 - vae_kl_loss: 10.0197\n",
      "Epoch 152/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9478 - vae_r_loss: 10.0303 - vae_kl_loss: 9.9175\n",
      "Epoch 153/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.9300 - vae_r_loss: 9.8672 - vae_kl_loss: 10.0628\n",
      "Epoch 154/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6475 - vae_r_loss: 9.6280 - vae_kl_loss: 10.0195\n",
      "Epoch 155/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6767 - vae_r_loss: 9.7222 - vae_kl_loss: 9.9545\n",
      "Epoch 156/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.7921 - vae_r_loss: 9.8778 - vae_kl_loss: 9.9143\n",
      "Epoch 157/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6879 - vae_r_loss: 9.6326 - vae_kl_loss: 10.0552\n",
      "Epoch 158/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7154 - vae_r_loss: 9.9408 - vae_kl_loss: 9.7746\n",
      "Epoch 159/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.7397 - vae_r_loss: 9.7428 - vae_kl_loss: 9.9969\n",
      "Epoch 160/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.6676 - vae_r_loss: 9.6473 - vae_kl_loss: 10.0203\n",
      "Epoch 161/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.6982 - vae_r_loss: 9.7335 - vae_kl_loss: 9.9647\n",
      "Epoch 162/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.7057 - vae_r_loss: 9.7064 - vae_kl_loss: 9.9993\n",
      "Epoch 163/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7054 - vae_r_loss: 9.8127 - vae_kl_loss: 9.8927A: 0s - loss: 19.9700 - vae_r_loss: 10.2389 - vae\n",
      "Epoch 164/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.6218 - vae_r_loss: 9.5741 - vae_kl_loss: 10.0476\n",
      "Epoch 165/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5724 - vae_r_loss: 9.6903 - vae_kl_loss: 9.8821\n",
      "Epoch 166/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5517 - vae_r_loss: 9.5667 - vae_kl_loss: 9.9850\n",
      "Epoch 167/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6843 - vae_r_loss: 9.7699 - vae_kl_loss: 9.9144\n",
      "Epoch 168/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.7616 - vae_r_loss: 9.7169 - vae_kl_loss: 10.0446\n",
      "Epoch 169/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6807 - vae_r_loss: 9.6184 - vae_kl_loss: 10.0623\n",
      "Epoch 170/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.5981 - vae_r_loss: 9.5544 - vae_kl_loss: 10.0436\n",
      "Epoch 171/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.7533 - vae_r_loss: 9.7418 - vae_kl_loss: 10.0115\n",
      "Epoch 172/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.7197 - vae_r_loss: 9.8545 - vae_kl_loss: 9.8653A: 1s - loss: 19.9504 - vae_r_loss: 10.07\n",
      "Epoch 173/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5856 - vae_r_loss: 9.6874 - vae_kl_loss: 9.8982\n",
      "Epoch 174/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6211 - vae_r_loss: 9.6992 - vae_kl_loss: 9.9219A: 1s - loss: 19.2926 - vae_r_loss: 9.4334 - va\n",
      "Epoch 175/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.6946 - vae_r_loss: 9.6648 - vae_kl_loss: 10.0299\n",
      "Epoch 176/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5525 - vae_r_loss: 9.4988 - vae_kl_loss: 10.0537\n",
      "Epoch 177/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6417 - vae_r_loss: 9.5627 - vae_kl_loss: 10.0790\n",
      "Epoch 178/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7197 - vae_r_loss: 9.7058 - vae_kl_loss: 10.0139\n",
      "Epoch 179/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7343 - vae_r_loss: 9.6176 - vae_kl_loss: 10.1167\n",
      "Epoch 180/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.6192 - vae_r_loss: 9.6167 - vae_kl_loss: 10.0026\n",
      "Epoch 181/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.5353 - vae_r_loss: 9.4738 - vae_kl_loss: 10.0615\n",
      "Epoch 182/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.3266 - vae_r_loss: 9.4770 - vae_kl_loss: 9.8496\n",
      "Epoch 183/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5982 - vae_r_loss: 9.7124 - vae_kl_loss: 9.8858\n",
      "Epoch 184/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7079 - vae_r_loss: 9.6482 - vae_kl_loss: 10.0597\n",
      "Epoch 185/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6759 - vae_r_loss: 9.6406 - vae_kl_loss: 10.0354\n",
      "Epoch 186/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 20.0053 - vae_r_loss: 9.7620 - vae_kl_loss: 10.2434\n",
      "Epoch 187/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6791 - vae_r_loss: 9.6356 - vae_kl_loss: 10.0435\n",
      "Epoch 188/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8010 - vae_r_loss: 9.6809 - vae_kl_loss: 10.1202\n",
      "Epoch 189/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.8948 - vae_r_loss: 9.8477 - vae_kl_loss: 10.0471\n",
      "Epoch 190/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6440 - vae_r_loss: 9.7155 - vae_kl_loss: 9.9286\n",
      "Epoch 191/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7344 - vae_r_loss: 9.7056 - vae_kl_loss: 10.0287\n",
      "Epoch 192/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.3909 - vae_r_loss: 9.4510 - vae_kl_loss: 9.9399\n",
      "Epoch 193/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.6252 - vae_r_loss: 9.5610 - vae_kl_loss: 10.0642\n",
      "Epoch 194/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.3978 - vae_r_loss: 9.4998 - vae_kl_loss: 9.8980\n",
      "Epoch 195/1000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 19.8863 - vae_r_loss: 9.7333 - vae_kl_loss: 10.1530\n",
      "Epoch 196/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4202 - vae_r_loss: 9.4611 - vae_kl_loss: 9.9592A: 1s - loss: 19.575\n",
      "Epoch 197/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4956 - vae_r_loss: 9.5404 - vae_kl_loss: 9.9552A: 1s - loss: 19.4953 - vae_r_loss: 9.4422 - \n",
      "Epoch 198/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5946 - vae_r_loss: 9.6458 - vae_kl_loss: 9.9488\n",
      "Epoch 199/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6418 - vae_r_loss: 9.7715 - vae_kl_loss: 9.8703\n",
      "Epoch 200/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4087 - vae_r_loss: 9.4312 - vae_kl_loss: 9.9776\n",
      "Epoch 201/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7441 - vae_r_loss: 9.6230 - vae_kl_loss: 10.1211\n",
      "Epoch 202/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5850 - vae_r_loss: 9.5333 - vae_kl_loss: 10.0517\n",
      "Epoch 203/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6094 - vae_r_loss: 9.5403 - vae_kl_loss: 10.0691\n",
      "Epoch 204/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8127 - vae_r_loss: 9.8219 - vae_kl_loss: 9.9908\n",
      "Epoch 205/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5461 - vae_r_loss: 9.4667 - vae_kl_loss: 10.0794\n",
      "Epoch 206/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5468 - vae_r_loss: 9.4684 - vae_kl_loss: 10.0784\n",
      "Epoch 207/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6212 - vae_r_loss: 9.7866 - vae_kl_loss: 9.8345\n",
      "Epoch 208/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.8394 - vae_r_loss: 9.7385 - vae_kl_loss: 10.1009\n",
      "Epoch 209/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4443 - vae_r_loss: 9.4540 - vae_kl_loss: 9.9903\n",
      "Epoch 210/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.3414 - vae_r_loss: 9.4552 - vae_kl_loss: 9.8862\n",
      "Epoch 211/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7365 - vae_r_loss: 9.5960 - vae_kl_loss: 10.1404\n",
      "Epoch 212/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4888 - vae_r_loss: 9.5448 - vae_kl_loss: 9.9440\n",
      "Epoch 213/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6175 - vae_r_loss: 9.5578 - vae_kl_loss: 10.0596\n",
      "Epoch 214/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6280 - vae_r_loss: 9.5113 - vae_kl_loss: 10.1167\n",
      "Epoch 215/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6437 - vae_r_loss: 9.6337 - vae_kl_loss: 10.0100\n",
      "Epoch 216/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5248 - vae_r_loss: 9.5774 - vae_kl_loss: 9.9474\n",
      "Epoch 217/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7571 - vae_r_loss: 9.6359 - vae_kl_loss: 10.1211\n",
      "Epoch 218/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6520 - vae_r_loss: 9.6911 - vae_kl_loss: 9.9609\n",
      "Epoch 219/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4327 - vae_r_loss: 9.4154 - vae_kl_loss: 10.0173\n",
      "Epoch 220/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4874 - vae_r_loss: 9.3441 - vae_kl_loss: 10.1432\n",
      "Epoch 221/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6286 - vae_r_loss: 9.5751 - vae_kl_loss: 10.0535\n",
      "Epoch 222/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.1846 - vae_r_loss: 9.3499 - vae_kl_loss: 9.8347\n",
      "Epoch 223/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6639 - vae_r_loss: 9.5197 - vae_kl_loss: 10.1443\n",
      "Epoch 224/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6300 - vae_r_loss: 9.5943 - vae_kl_loss: 10.0357\n",
      "Epoch 225/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.7792 - vae_r_loss: 9.7497 - vae_kl_loss: 10.0296\n",
      "Epoch 226/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5327 - vae_r_loss: 9.3678 - vae_kl_loss: 10.1649\n",
      "Epoch 227/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6583 - vae_r_loss: 9.6024 - vae_kl_loss: 10.0559\n",
      "Epoch 228/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6063 - vae_r_loss: 9.6883 - vae_kl_loss: 9.9180\n",
      "Epoch 229/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5322 - vae_r_loss: 9.4090 - vae_kl_loss: 10.1233\n",
      "Epoch 230/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5604 - vae_r_loss: 9.4371 - vae_kl_loss: 10.1232\n",
      "Epoch 231/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.6323 - vae_r_loss: 9.5140 - vae_kl_loss: 10.1182\n",
      "Epoch 232/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5866 - vae_r_loss: 9.5231 - vae_kl_loss: 10.0634\n",
      "Epoch 233/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.3849 - vae_r_loss: 9.3596 - vae_kl_loss: 10.0253: 0s - loss: 19.2851 - vae_r_loss: 9.3601 - vae_kl_lo\n",
      "Epoch 234/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.3031 - vae_r_loss: 9.3643 - vae_kl_loss: 9.9388\n",
      "Epoch 235/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5964 - vae_r_loss: 9.4679 - vae_kl_loss: 10.1285\n",
      "Epoch 236/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4459 - vae_r_loss: 9.5820 - vae_kl_loss: 9.8639\n",
      "Epoch 237/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.4756 - vae_r_loss: 9.5362 - vae_kl_loss: 9.9394\n",
      "Epoch 238/1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 19.5905 - vae_r_loss: 9.5896 - vae_kl_loss: 10.0009\n",
      "Epoch 239/1000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 19.5213 - vae_r_loss: 9.4932 - vae_kl_loss: 10.0281\n",
      "Epoch 240/1000\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 19.8116 - vae_r_loss: 9.5795 - vae_kl_loss: 10.2321\n",
      "Epoch 241/1000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 19.4737 - vae_r_loss: 9.4398 - vae_kl_loss: 10.0339\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s 5ms/step - loss: 19.5042 - vae_r_loss: 9.5272 - vae_kl_loss: 9.9770\n",
      "Epoch 243/1000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 19.6275 - vae_r_loss: 9.6159 - vae_kl_loss: 10.0116\n",
      "Epoch 244/1000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 19.3341 - vae_r_loss: 9.4217 - vae_kl_loss: 9.9125\n",
      "Epoch 245/1000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 19.3972 - vae_r_loss: 9.3295 - vae_kl_loss: 10.0677: 3s - loss: 19.1\n",
      "Epoch 246/1000\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 19.4376 - vae_r_loss: 9.3672 - vae_kl_loss: 10.0704\n",
      "Epoch 247/1000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 19.5251 - vae_r_loss: 9.4119 - vae_kl_loss: 10.1133\n",
      "Epoch 248/1000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 19.5013 - vae_r_loss: 9.4061 - vae_kl_loss: 10.0952\n",
      "Epoch 249/1000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 19.3196 - vae_r_loss: 9.4280 - vae_kl_loss: 9.8916\n",
      "Epoch 250/1000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 19.4105 - vae_r_loss: 9.3750 - vae_kl_loss: 10.0355\n",
      "Epoch 251/1000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 19.4851 - vae_r_loss: 9.3998 - vae_kl_loss: 10.0852\n",
      "Epoch 252/1000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 19.3417 - vae_r_loss: 9.2964 - vae_kl_loss: 10.0454\n",
      "Epoch 253/1000\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 19.6202 - vae_r_loss: 9.5609 - vae_kl_loss: 10.0592\n",
      "Epoch 254/1000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 19.8288 - vae_r_loss: 9.7564 - vae_kl_loss: 10.0723\n",
      "Epoch 255/1000\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 19.5008 - vae_r_loss: 9.5034 - vae_kl_loss: 9.9974\n",
      "Epoch 256/1000\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 19.5221 - vae_r_loss: 9.3288 - vae_kl_loss: 10.1932\n",
      "Epoch 257/1000\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 19.4069 - vae_r_loss: 9.4697 - vae_kl_loss: 9.9371\n",
      "Epoch 258/1000\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 19.4565 - vae_r_loss: 9.3713 - vae_kl_loss: 10.0853\n",
      "Epoch 259/1000\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 19.5159 - vae_r_loss: 9.5483 - vae_kl_loss: 9.9676\n",
      "Epoch 260/1000\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 19.6814 - vae_r_loss: 9.6054 - vae_kl_loss: 10.0760\n",
      "Epoch 261/1000\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 19.5511 - vae_r_loss: 9.3379 - vae_kl_loss: 10.2132\n",
      "Epoch 262/1000\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 19.4240 - vae_r_loss: 9.3943 - vae_kl_loss: 10.0297\n",
      "Epoch 263/1000\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 19.6101 - vae_r_loss: 9.5723 - vae_kl_loss: 10.0378\n",
      "Epoch 264/1000\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 19.4056 - vae_r_loss: 9.4269 - vae_kl_loss: 9.9787\n",
      "Epoch 265/1000\n",
      " 320/1000 [========>.....................] - ETA: 8s - loss: 19.6865 - vae_r_loss: 9.4021 - vae_kl_loss: 10.2844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3bf518778d1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mINITIAL_EPOCH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4ab4cbf42ee1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch, lr_decay)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         )\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3735\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3736\u001b[0m         expand_composites=True)\n\u001b[0;32m   3737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3735\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3736\u001b[0m         expand_composites=True)\n\u001b[0;32m   3737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.00075\n",
    "R_LOSS_FACTOR = 1000\n",
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "\n",
    "vae.train(\n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")\n",
    "vae.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "shape_bef_flat (8, 8, 512)\n",
      "shape_aft_flat Tensor(\"flatten_1/Reshape:0\", shape=(None, None), dtype=float32)\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "encoder_output:  Tensor(\"encoder_output/add:0\", shape=(None, 400), dtype=float32)\n",
      "dec_input Tensor(\"decoder_input:0\", shape=(None, 400), dtype=float32)\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "dec_inputtii Tensor(\"decoder_input:0\", shape=(None, 400), dtype=float32)\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Epoch 1/250\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_keras_scratch_graph_3141 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  32/1000 [..............................] - ETA: 3:55 - loss: 11.4626 - vae_r_loss: 11.2975 - vae_kl_loss: 0.1650Executing op __inference_keras_scratch_graph_3278 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " 128/1000 [==>...........................] - ETA: 1:00 - loss: 13.0819 - vae_r_loss: 12.4350 - vae_kl_loss: 0.6469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\envs\\ml20\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.442000). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 11s 11ms/step - loss: 13.8191 - vae_r_loss: 13.6566 - vae_kl_loss: 0.1625\n",
      "Epoch 2/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 12.6527 - vae_r_loss: 11.7592 - vae_kl_loss: 0.8935\n",
      "Epoch 3/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.6451 - vae_r_loss: 10.2850 - vae_kl_loss: 1.3601\n",
      "Epoch 4/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.7820 - vae_r_loss: 10.3711 - vae_kl_loss: 1.4110\n",
      "Epoch 5/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.9178 - vae_r_loss: 10.5241 - vae_kl_loss: 1.3937\n",
      "Epoch 6/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.4085 - vae_r_loss: 10.0032 - vae_kl_loss: 1.4053\n",
      "Epoch 7/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.1361 - vae_r_loss: 9.6928 - vae_kl_loss: 1.4433\n",
      "Epoch 8/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.3421 - vae_r_loss: 9.9195 - vae_kl_loss: 1.4226\n",
      "Epoch 9/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.4683 - vae_r_loss: 9.9487 - vae_kl_loss: 1.5196\n",
      "Epoch 10/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.4158 - vae_r_loss: 9.9024 - vae_kl_loss: 1.5134\n",
      "Epoch 11/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.4236 - vae_r_loss: 9.9519 - vae_kl_loss: 1.4717\n",
      "Epoch 12/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.1834 - vae_r_loss: 9.7290 - vae_kl_loss: 1.4544\n",
      "Epoch 13/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.1883 - vae_r_loss: 9.7623 - vae_kl_loss: 1.4259\n",
      "Epoch 14/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.3983 - vae_r_loss: 9.9696 - vae_kl_loss: 1.4287\n",
      "Epoch 15/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.2198 - vae_r_loss: 9.8480 - vae_kl_loss: 1.3718\n",
      "Epoch 16/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.1116 - vae_r_loss: 9.7006 - vae_kl_loss: 1.4111\n",
      "Epoch 17/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.3500 - vae_r_loss: 9.8734 - vae_kl_loss: 1.4766\n",
      "Epoch 18/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.2237 - vae_r_loss: 9.7515 - vae_kl_loss: 1.4722\n",
      "Epoch 19/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.1841 - vae_r_loss: 9.7223 - vae_kl_loss: 1.4617A: 0s - loss: 11.1722 - vae_r_loss: 9.7084 - vae_kl_loss: 1.463\n",
      "Epoch 20/250\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.2049 - vae_r_loss: 9.7116 - vae_kl_loss: 1.4934\n",
      "Epoch 21/250\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.2045 - vae_r_loss: 9.7609 - vae_kl_loss: 1.4436\n",
      "Epoch 22/250\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 11.1683 - vae_r_loss: 9.6888 - vae_kl_loss: 1.4794\n",
      "Epoch 23/250\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 11.3116 - vae_r_loss: 9.8310 - vae_kl_loss: 1.4806\n",
      "Epoch 24/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.2044 - vae_r_loss: 9.7740 - vae_kl_loss: 1.4304\n",
      "Epoch 25/250\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 11.0340 - vae_r_loss: 9.5854 - vae_kl_loss: 1.4486\n",
      "Epoch 26/250\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 11.3470 - vae_r_loss: 9.8469 - vae_kl_loss: 1.5001\n",
      "Epoch 27/250\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 11.1260 - vae_r_loss: 9.6495 - vae_kl_loss: 1.4765\n",
      "Epoch 28/250\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 11.0936 - vae_r_loss: 9.6456 - vae_kl_loss: 1.4481\n",
      "Epoch 29/250\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 11.2788 - vae_r_loss: 9.8232 - vae_kl_loss: 1.4556\n",
      "Epoch 30/250\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 11.0149 - vae_r_loss: 9.6407 - vae_kl_loss: 1.3742\n",
      "Epoch 31/250\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 11.1357 - vae_r_loss: 9.6338 - vae_kl_loss: 1.5018\n",
      "Epoch 32/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.2033 - vae_r_loss: 9.7025 - vae_kl_loss: 1.5009\n",
      "Epoch 33/250\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 11.1859 - vae_r_loss: 9.7300 - vae_kl_loss: 1.4559\n",
      "Epoch 34/250\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 11.0665 - vae_r_loss: 9.5972 - vae_kl_loss: 1.4692\n",
      "Epoch 35/250\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 11.0173 - vae_r_loss: 9.6001 - vae_kl_loss: 1.4171\n",
      "Epoch 36/250\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 11.2045 - vae_r_loss: 9.7085 - vae_kl_loss: 1.4960\n",
      "Epoch 37/250\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 11.0999 - vae_r_loss: 9.5955 - vae_kl_loss: 1.5043\n",
      "Epoch 38/250\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 11.2118 - vae_r_loss: 9.7493 - vae_kl_loss: 1.4624\n",
      "Epoch 39/250\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 11.1347 - vae_r_loss: 9.6757 - vae_kl_loss: 1.4589\n",
      "Epoch 40/250\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 11.1133 - vae_r_loss: 9.6951 - vae_kl_loss: 1.4181\n",
      "Epoch 41/250\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 10.9563 - vae_r_loss: 9.5543 - vae_kl_loss: 1.4020\n",
      "Epoch 42/250\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 11.2501 - vae_r_loss: 9.8055 - vae_kl_loss: 1.4446\n",
      "Epoch 43/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.0330 - vae_r_loss: 9.5756 - vae_kl_loss: 1.4573\n",
      "Epoch 44/250\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 11.0436 - vae_r_loss: 9.6023 - vae_kl_loss: 1.4413\n",
      "Epoch 45/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 10.9214 - vae_r_loss: 9.5526 - vae_kl_loss: 1.3688\n",
      "Epoch 46/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.1257 - vae_r_loss: 9.6685 - vae_kl_loss: 1.4572\n",
      "Epoch 47/250\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 11.1099 - vae_r_loss: 9.6336 - vae_kl_loss: 1.4763\n",
      "Epoch 48/250\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 11.0489 - vae_r_loss: 9.6315 - vae_kl_loss: 1.4174\n",
      "Epoch 49/250\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 10.9335 - vae_r_loss: 9.5690 - vae_kl_loss: 1.3644\n",
      "Epoch 50/250\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 11.0495 - vae_r_loss: 9.6273 - vae_kl_loss: 1.4222\n",
      "Epoch 51/250\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 11.1275 - vae_r_loss: 9.6990 - vae_kl_loss: 1.4284\n",
      "Epoch 52/250\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 11.1478 - vae_r_loss: 9.6997 - vae_kl_loss: 1.4480\n",
      "Epoch 53/250\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 11.0982 - vae_r_loss: 9.6662 - vae_kl_loss: 1.4320\n",
      "Epoch 54/250\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 10.9346 - vae_r_loss: 9.5687 - vae_kl_loss: 1.3659\n",
      "Epoch 55/250\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 10.9777 - vae_r_loss: 9.5996 - vae_kl_loss: 1.3782\n",
      "Epoch 56/250\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 11.0272 - vae_r_loss: 9.5145 - vae_kl_loss: 1.5127\n",
      "Epoch 57/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.0436 - vae_r_loss: 9.6506 - vae_kl_loss: 1.3930\n",
      "Epoch 58/250\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 11.2353 - vae_r_loss: 9.7454 - vae_kl_loss: 1.4899A: 3s - loss: 11.1206 - vae_r_loss: 9.6979 - \n",
      "Epoch 59/250\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 11.0162 - vae_r_loss: 9.6182 - vae_kl_loss: 1.3981\n",
      "Epoch 60/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.0912 - vae_r_loss: 9.6041 - vae_kl_loss: 1.4872\n",
      "Epoch 61/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 11.1127 - vae_r_loss: 9.7286 - vae_kl_loss: 1.3841\n",
      "Epoch 62/250\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 11.0932 - vae_r_loss: 9.6157 - vae_kl_loss: 1.4775\n",
      "Epoch 63/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 12s 12ms/step - loss: 10.9425 - vae_r_loss: 9.5118 - vae_kl_loss: 1.4307\n",
      "Epoch 64/250\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 10.8629 - vae_r_loss: 9.4317 - vae_kl_loss: 1.4312\n",
      "Epoch 65/250\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 11.0335 - vae_r_loss: 9.5802 - vae_kl_loss: 1.4533\n",
      "Epoch 66/250\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 11.1512 - vae_r_loss: 9.6411 - vae_kl_loss: 1.5101\n",
      "Epoch 67/250\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 11.2470 - vae_r_loss: 9.7899 - vae_kl_loss: 1.4571\n",
      "Epoch 68/250\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 11.1746 - vae_r_loss: 9.6899 - vae_kl_loss: 1.4847\n",
      "Epoch 69/250\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 11.0463 - vae_r_loss: 9.6304 - vae_kl_loss: 1.4160\n",
      "Epoch 70/250\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 11.1331 - vae_r_loss: 9.6397 - vae_kl_loss: 1.4933\n",
      "Epoch 71/250\n",
      "  64/1000 [>.............................] - ETA: 12s - loss: 11.2047 - vae_r_loss: 9.8616 - vae_kl_loss: 1.3431"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5d1c7d9cf90e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mINITIAL_EPOCH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4ab4cbf42ee1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch, lr_decay)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         )\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3735\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3736\u001b[0m         expand_composites=True)\n\u001b[0;32m   3737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3735\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3736\u001b[0m         expand_composites=True)\n\u001b[0;32m   3737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml20\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    908\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "#Higher Z Dim and Lower R Loss Factor\n",
    "\n",
    "vae = VariationalAutoencoder(\n",
    "    input_dim = (32,32,3)\n",
    "    , encoder_conv_filters = [128,128,128,512]\n",
    "    , encoder_conv_kernel_size = [2,2,3,4]\n",
    "    , encoder_conv_strides = [1,1,2,2]\n",
    "    , decoder_conv_t_filters = [512,128,128,3]\n",
    "    , decoder_conv_t_kernel_size = [4,3,2,2]\n",
    "    , decoder_conv_t_strides = [2,2,1,1]\n",
    "    , z_dim = 400\n",
    ")\n",
    "vae.save(RUN_FOLDER)\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 250\n",
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 250\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "\n",
    "vae.train(\n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")\n",
    "vae.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "Executing op __inference_keras_scratch_graph_2269545 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 22.7694 - vae_r_loss: 13.4576 - vae_kl_loss: 9.3118\n",
      "Epoch 2/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7356 - vae_r_loss: 13.4230 - vae_kl_loss: 9.3126\n",
      "Epoch 3/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6703 - vae_r_loss: 13.3638 - vae_kl_loss: 9.3065\n",
      "Epoch 4/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7083 - vae_r_loss: 13.4114 - vae_kl_loss: 9.2969\n",
      "Epoch 5/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7976 - vae_r_loss: 13.4947 - vae_kl_loss: 9.3028\n",
      "Epoch 6/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7647 - vae_r_loss: 13.4429 - vae_kl_loss: 9.3219: 1s - loss:\n",
      "Epoch 7/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7357 - vae_r_loss: 13.4220 - vae_kl_loss: 9.3138\n",
      "Epoch 8/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7892 - vae_r_loss: 13.4698 - vae_kl_loss: 9.3194\n",
      "Epoch 9/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8430 - vae_r_loss: 13.4984 - vae_kl_loss: 9.3446\n",
      "Epoch 10/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7483 - vae_r_loss: 13.3951 - vae_kl_loss: 9.3532\n",
      "Epoch 11/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7802 - vae_r_loss: 13.4525 - vae_kl_loss: 9.3277\n",
      "Epoch 12/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6859 - vae_r_loss: 13.3712 - vae_kl_loss: 9.3148\n",
      "Epoch 13/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7348 - vae_r_loss: 13.4361 - vae_kl_loss: 9.2987\n",
      "Epoch 14/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7361 - vae_r_loss: 13.4393 - vae_kl_loss: 9.2968\n",
      "Epoch 15/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7512 - vae_r_loss: 13.4466 - vae_kl_loss: 9.3046\n",
      "Epoch 16/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7842 - vae_r_loss: 13.4653 - vae_kl_loss: 9.3189\n",
      "Epoch 17/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7122 - vae_r_loss: 13.3847 - vae_kl_loss: 9.3274\n",
      "Epoch 18/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7183 - vae_r_loss: 13.4048 - vae_kl_loss: 9.3135\n",
      "Epoch 19/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6561 - vae_r_loss: 13.3480 - vae_kl_loss: 9.3081\n",
      "Epoch 20/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6967 - vae_r_loss: 13.4117 - vae_kl_loss: 9.2849\n",
      "Epoch 21/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7461 - vae_r_loss: 13.4612 - vae_kl_loss: 9.2848\n",
      "Epoch 22/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7398 - vae_r_loss: 13.4462 - vae_kl_loss: 9.2936\n",
      "Epoch 23/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7280 - vae_r_loss: 13.4187 - vae_kl_loss: 9.3093: 0s - loss: 22.7443 - vae_r_loss: 13.4335\n",
      "Epoch 24/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7624 - vae_r_loss: 13.4668 - vae_kl_loss: 9.2956\n",
      "Epoch 25/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7640 - vae_r_loss: 13.4712 - vae_kl_loss: 9.2927\n",
      "Epoch 26/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7053 - vae_r_loss: 13.4133 - vae_kl_loss: 9.2921\n",
      "Epoch 27/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7725 - vae_r_loss: 13.4731 - vae_kl_loss: 9.2994\n",
      "Epoch 28/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7412 - vae_r_loss: 13.4263 - vae_kl_loss: 9.3149\n",
      "Epoch 29/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8233 - vae_r_loss: 13.4939 - vae_kl_loss: 9.3293\n",
      "Epoch 30/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7127 - vae_r_loss: 13.3844 - vae_kl_loss: 9.3283\n",
      "Epoch 31/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7432 - vae_r_loss: 13.4284 - vae_kl_loss: 9.3148\n",
      "Epoch 32/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7447 - vae_r_loss: 13.4115 - vae_kl_loss: 9.3332\n",
      "Epoch 33/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7757 - vae_r_loss: 13.4449 - vae_kl_loss: 9.3307\n",
      "Epoch 34/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7729 - vae_r_loss: 13.4364 - vae_kl_loss: 9.3365\n",
      "Epoch 35/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7152 - vae_r_loss: 13.3941 - vae_kl_loss: 9.3210\n",
      "Epoch 36/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7557 - vae_r_loss: 13.4396 - vae_kl_loss: 9.3162\n",
      "Epoch 37/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7253 - vae_r_loss: 13.4118 - vae_kl_loss: 9.3135\n",
      "Epoch 38/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7713 - vae_r_loss: 13.4696 - vae_kl_loss: 9.3017\n",
      "Epoch 39/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7741 - vae_r_loss: 13.4694 - vae_kl_loss: 9.3047\n",
      "Epoch 40/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7419 - vae_r_loss: 13.4211 - vae_kl_loss: 9.3209\n",
      "Epoch 41/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7653 - vae_r_loss: 13.4344 - vae_kl_loss: 9.3309\n",
      "Epoch 42/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7530 - vae_r_loss: 13.4212 - vae_kl_loss: 9.3317\n",
      "Epoch 43/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7647 - vae_r_loss: 13.4314 - vae_kl_loss: 9.3332\n",
      "Epoch 44/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7077 - vae_r_loss: 13.3938 - vae_kl_loss: 9.3139\n",
      "Epoch 45/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7417 - vae_r_loss: 13.4474 - vae_kl_loss: 9.2944\n",
      "Epoch 46/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7430 - vae_r_loss: 13.4498 - vae_kl_loss: 9.2932\n",
      "Epoch 47/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7488 - vae_r_loss: 13.4541 - vae_kl_loss: 9.2947\n",
      "Epoch 48/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7630 - vae_r_loss: 13.4580 - vae_kl_loss: 9.3050\n",
      "Epoch 49/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7406 - vae_r_loss: 13.4271 - vae_kl_loss: 9.3135\n",
      "Epoch 50/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7340 - vae_r_loss: 13.4259 - vae_kl_loss: 9.3081\n",
      "Epoch 51/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7184 - vae_r_loss: 13.4259 - vae_kl_loss: 9.2925\n",
      "Epoch 52/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7018 - vae_r_loss: 13.4008 - vae_kl_loss: 9.3009\n",
      "Epoch 53/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7623 - vae_r_loss: 13.4580 - vae_kl_loss: 9.3043\n",
      "Epoch 54/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7439 - vae_r_loss: 13.4153 - vae_kl_loss: 9.3287\n",
      "Epoch 55/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8030 - vae_r_loss: 13.4735 - vae_kl_loss: 9.3296\n",
      "Epoch 56/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7823 - vae_r_loss: 13.4330 - vae_kl_loss: 9.3494\n",
      "Epoch 57/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6693 - vae_r_loss: 13.3350 - vae_kl_loss: 9.3344\n",
      "Epoch 58/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7368 - vae_r_loss: 13.4212 - vae_kl_loss: 9.3156\n",
      "Epoch 59/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7467 - vae_r_loss: 13.4265 - vae_kl_loss: 9.3202\n",
      "Epoch 60/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7692 - vae_r_loss: 13.4592 - vae_kl_loss: 9.3101\n",
      "Epoch 61/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7854 - vae_r_loss: 13.4612 - vae_kl_loss: 9.3241\n",
      "Epoch 62/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7309 - vae_r_loss: 13.4196 - vae_kl_loss: 9.3113\n",
      "Epoch 63/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7188 - vae_r_loss: 13.4067 - vae_kl_loss: 9.3120\n",
      "Epoch 64/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7163 - vae_r_loss: 13.4253 - vae_kl_loss: 9.2910\n",
      "Epoch 65/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8098 - vae_r_loss: 13.5004 - vae_kl_loss: 9.3095\n",
      "Epoch 66/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7108 - vae_r_loss: 13.3876 - vae_kl_loss: 9.3232\n",
      "Epoch 67/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6986 - vae_r_loss: 13.3863 - vae_kl_loss: 9.3123\n",
      "Epoch 68/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7205 - vae_r_loss: 13.4144 - vae_kl_loss: 9.3061\n",
      "Epoch 69/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7800 - vae_r_loss: 13.4682 - vae_kl_loss: 9.3118\n",
      "Epoch 70/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7904 - vae_r_loss: 13.4651 - vae_kl_loss: 9.3252\n",
      "Epoch 71/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7269 - vae_r_loss: 13.4047 - vae_kl_loss: 9.3222\n",
      "Epoch 72/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7479 - vae_r_loss: 13.4247 - vae_kl_loss: 9.3232\n",
      "Epoch 73/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7185 - vae_r_loss: 13.3901 - vae_kl_loss: 9.3283\n",
      "Epoch 74/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7480 - vae_r_loss: 13.4359 - vae_kl_loss: 9.3121\n",
      "Epoch 75/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7422 - vae_r_loss: 13.4425 - vae_kl_loss: 9.2997\n",
      "Epoch 76/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7307 - vae_r_loss: 13.4287 - vae_kl_loss: 9.3020\n",
      "Epoch 77/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7754 - vae_r_loss: 13.4670 - vae_kl_loss: 9.3083\n",
      "Epoch 78/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7264 - vae_r_loss: 13.4162 - vae_kl_loss: 9.3102\n",
      "Epoch 79/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7209 - vae_r_loss: 13.4267 - vae_kl_loss: 9.2942\n",
      "Epoch 80/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7698 - vae_r_loss: 13.4632 - vae_kl_loss: 9.3066\n",
      "Epoch 81/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7319 - vae_r_loss: 13.4329 - vae_kl_loss: 9.2990\n",
      "Epoch 82/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7543 - vae_r_loss: 13.4518 - vae_kl_loss: 9.3025\n",
      "Epoch 83/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7193 - vae_r_loss: 13.4157 - vae_kl_loss: 9.3036\n",
      "Epoch 84/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7192 - vae_r_loss: 13.4076 - vae_kl_loss: 9.3116\n",
      "Epoch 85/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7626 - vae_r_loss: 13.4500 - vae_kl_loss: 9.3126\n",
      "Epoch 86/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7683 - vae_r_loss: 13.4589 - vae_kl_loss: 9.3095\n",
      "Epoch 87/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7033 - vae_r_loss: 13.3991 - vae_kl_loss: 9.3041\n",
      "Epoch 88/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7457 - vae_r_loss: 13.4492 - vae_kl_loss: 9.2966\n",
      "Epoch 89/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7954 - vae_r_loss: 13.4726 - vae_kl_loss: 9.3227\n",
      "Epoch 90/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7664 - vae_r_loss: 13.4243 - vae_kl_loss: 9.3421\n",
      "Epoch 91/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7496 - vae_r_loss: 13.4079 - vae_kl_loss: 9.3416\n",
      "Epoch 92/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8084 - vae_r_loss: 13.4812 - vae_kl_loss: 9.3272\n",
      "Epoch 93/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7613 - vae_r_loss: 13.4398 - vae_kl_loss: 9.3215\n",
      "Epoch 94/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7775 - vae_r_loss: 13.4504 - vae_kl_loss: 9.3271\n",
      "Epoch 95/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6983 - vae_r_loss: 13.3796 - vae_kl_loss: 9.3187\n",
      "Epoch 96/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7202 - vae_r_loss: 13.4053 - vae_kl_loss: 9.3149\n",
      "Epoch 97/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7207 - vae_r_loss: 13.3928 - vae_kl_loss: 9.3278\n",
      "Epoch 98/250\n",
      "5000/5000 [==============================] - ETA: 0s - loss: 22.7128 - vae_r_loss: 13.3971 - vae_kl_loss: 9.31 - 8s 2ms/step - loss: 22.7127 - vae_r_loss: 13.3949 - vae_kl_loss: 9.3177\n",
      "Epoch 99/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7381 - vae_r_loss: 13.4256 - vae_kl_loss: 9.3125\n",
      "Epoch 100/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7196 - vae_r_loss: 13.4030 - vae_kl_loss: 9.3166\n",
      "Epoch 101/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7291 - vae_r_loss: 13.4110 - vae_kl_loss: 9.3181\n",
      "Epoch 102/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6868 - vae_r_loss: 13.3677 - vae_kl_loss: 9.3191\n",
      "Epoch 103/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7206 - vae_r_loss: 13.4015 - vae_kl_loss: 9.3191\n",
      "Epoch 104/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7451 - vae_r_loss: 13.4455 - vae_kl_loss: 9.2996\n",
      "Epoch 105/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7393 - vae_r_loss: 13.4182 - vae_kl_loss: 9.3211\n",
      "Epoch 106/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7476 - vae_r_loss: 13.4207 - vae_kl_loss: 9.3270\n",
      "Epoch 107/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8072 - vae_r_loss: 13.4547 - vae_kl_loss: 9.3526\n",
      "Epoch 108/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7437 - vae_r_loss: 13.3991 - vae_kl_loss: 9.3446\n",
      "Epoch 109/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7262 - vae_r_loss: 13.3970 - vae_kl_loss: 9.3291\n",
      "Epoch 110/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7490 - vae_r_loss: 13.4311 - vae_kl_loss: 9.3178: 1s - loss: 22.7526 -\n",
      "Epoch 111/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8063 - vae_r_loss: 13.4765 - vae_kl_loss: 9.3298\n",
      "Epoch 112/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7224 - vae_r_loss: 13.4033 - vae_kl_loss: 9.3190\n",
      "Epoch 113/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7486 - vae_r_loss: 13.4440 - vae_kl_loss: 9.3045\n",
      "Epoch 114/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7059 - vae_r_loss: 13.4101 - vae_kl_loss: 9.2958\n",
      "Epoch 115/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7715 - vae_r_loss: 13.4741 - vae_kl_loss: 9.2973\n",
      "Epoch 116/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7444 - vae_r_loss: 13.4223 - vae_kl_loss: 9.3222\n",
      "Epoch 117/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7930 - vae_r_loss: 13.4682 - vae_kl_loss: 9.3248\n",
      "Epoch 118/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7321 - vae_r_loss: 13.4076 - vae_kl_loss: 9.3245\n",
      "Epoch 119/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7320 - vae_r_loss: 13.4112 - vae_kl_loss: 9.3208\n",
      "Epoch 120/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7588 - vae_r_loss: 13.4350 - vae_kl_loss: 9.3238\n",
      "Epoch 121/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7532 - vae_r_loss: 13.4258 - vae_kl_loss: 9.3274\n",
      "Epoch 122/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7416 - vae_r_loss: 13.4328 - vae_kl_loss: 9.3089\n",
      "Epoch 123/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7744 - vae_r_loss: 13.4576 - vae_kl_loss: 9.3168\n",
      "Epoch 124/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7481 - vae_r_loss: 13.4249 - vae_kl_loss: 9.3232\n",
      "Epoch 125/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6800 - vae_r_loss: 13.3653 - vae_kl_loss: 9.3147\n",
      "Epoch 126/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6786 - vae_r_loss: 13.3845 - vae_kl_loss: 9.2941\n",
      "Epoch 127/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6855 - vae_r_loss: 13.3912 - vae_kl_loss: 9.2943\n",
      "Epoch 128/250\n",
      "5000/5000 [==============================] - ETA: 0s - loss: 22.7621 - vae_r_loss: 13.4595 - vae_kl_loss: 9.30 - 8s 2ms/step - loss: 22.7670 - vae_r_loss: 13.4681 - vae_kl_loss: 9.2989\n",
      "Epoch 129/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6929 - vae_r_loss: 13.3859 - vae_kl_loss: 9.3069\n",
      "Epoch 130/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7545 - vae_r_loss: 13.4401 - vae_kl_loss: 9.3145\n",
      "Epoch 131/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7081 - vae_r_loss: 13.4042 - vae_kl_loss: 9.3039\n",
      "Epoch 132/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7623 - vae_r_loss: 13.4564 - vae_kl_loss: 9.3059\n",
      "Epoch 133/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7295 - vae_r_loss: 13.4204 - vae_kl_loss: 9.3091\n",
      "Epoch 134/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7501 - vae_r_loss: 13.4449 - vae_kl_loss: 9.3053\n",
      "Epoch 135/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7779 - vae_r_loss: 13.4644 - vae_kl_loss: 9.3135\n",
      "Epoch 136/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6748 - vae_r_loss: 13.3547 - vae_kl_loss: 9.3200\n",
      "Epoch 137/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6771 - vae_r_loss: 13.3767 - vae_kl_loss: 9.3005\n",
      "Epoch 138/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7909 - vae_r_loss: 13.4962 - vae_kl_loss: 9.2948\n",
      "Epoch 139/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7744 - vae_r_loss: 13.4725 - vae_kl_loss: 9.3018\n",
      "Epoch 140/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7728 - vae_r_loss: 13.4436 - vae_kl_loss: 9.3292\n",
      "Epoch 141/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7341 - vae_r_loss: 13.4232 - vae_kl_loss: 9.3108\n",
      "Epoch 142/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7320 - vae_r_loss: 13.4185 - vae_kl_loss: 9.3136\n",
      "Epoch 143/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7877 - vae_r_loss: 13.4740 - vae_kl_loss: 9.3137\n",
      "Epoch 144/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7746 - vae_r_loss: 13.4340 - vae_kl_loss: 9.3406\n",
      "Epoch 145/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7700 - vae_r_loss: 13.4361 - vae_kl_loss: 9.3339\n",
      "Epoch 146/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7512 - vae_r_loss: 13.4166 - vae_kl_loss: 9.3346\n",
      "Epoch 147/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7341 - vae_r_loss: 13.4301 - vae_kl_loss: 9.3040\n",
      "Epoch 148/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7253 - vae_r_loss: 13.4139 - vae_kl_loss: 9.3114\n",
      "Epoch 149/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7451 - vae_r_loss: 13.4325 - vae_kl_loss: 9.3125\n",
      "Epoch 150/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7252 - vae_r_loss: 13.4198 - vae_kl_loss: 9.3053\n",
      "Epoch 151/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7189 - vae_r_loss: 13.4235 - vae_kl_loss: 9.2953\n",
      "Epoch 152/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7482 - vae_r_loss: 13.4530 - vae_kl_loss: 9.2952\n",
      "Epoch 153/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7774 - vae_r_loss: 13.4693 - vae_kl_loss: 9.3081\n",
      "Epoch 154/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7539 - vae_r_loss: 13.4324 - vae_kl_loss: 9.3215\n",
      "Epoch 155/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7340 - vae_r_loss: 13.4304 - vae_kl_loss: 9.3036\n",
      "Epoch 156/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8106 - vae_r_loss: 13.4929 - vae_kl_loss: 9.3177\n",
      "Epoch 157/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7709 - vae_r_loss: 13.4355 - vae_kl_loss: 9.3355\n",
      "Epoch 158/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7531 - vae_r_loss: 13.4250 - vae_kl_loss: 9.3282\n",
      "Epoch 159/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7752 - vae_r_loss: 13.4391 - vae_kl_loss: 9.3360\n",
      "Epoch 160/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7855 - vae_r_loss: 13.4435 - vae_kl_loss: 9.3420\n",
      "Epoch 161/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7697 - vae_r_loss: 13.4337 - vae_kl_loss: 9.3360\n",
      "Epoch 162/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7388 - vae_r_loss: 13.4074 - vae_kl_loss: 9.3314\n",
      "Epoch 163/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8011 - vae_r_loss: 13.4689 - vae_kl_loss: 9.3323\n",
      "Epoch 164/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7366 - vae_r_loss: 13.4090 - vae_kl_loss: 9.3276\n",
      "Epoch 165/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6941 - vae_r_loss: 13.3786 - vae_kl_loss: 9.3155\n",
      "Epoch 166/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7187 - vae_r_loss: 13.4029 - vae_kl_loss: 9.3158\n",
      "Epoch 167/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7385 - vae_r_loss: 13.4285 - vae_kl_loss: 9.3101\n",
      "Epoch 168/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7309 - vae_r_loss: 13.4168 - vae_kl_loss: 9.3141\n",
      "Epoch 169/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7255 - vae_r_loss: 13.4071 - vae_kl_loss: 9.3183\n",
      "Epoch 170/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6863 - vae_r_loss: 13.3643 - vae_kl_loss: 9.3221\n",
      "Epoch 171/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7484 - vae_r_loss: 13.4422 - vae_kl_loss: 9.3062\n",
      "Epoch 172/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8053 - vae_r_loss: 13.4813 - vae_kl_loss: 9.3239\n",
      "Epoch 173/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7240 - vae_r_loss: 13.3936 - vae_kl_loss: 9.3304\n",
      "Epoch 174/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7567 - vae_r_loss: 13.4255 - vae_kl_loss: 9.3312\n",
      "Epoch 175/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6787 - vae_r_loss: 13.3611 - vae_kl_loss: 9.3176\n",
      "Epoch 176/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7288 - vae_r_loss: 13.4224 - vae_kl_loss: 9.3064\n",
      "Epoch 177/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7682 - vae_r_loss: 13.4548 - vae_kl_loss: 9.3134\n",
      "Epoch 178/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7727 - vae_r_loss: 13.4315 - vae_kl_loss: 9.3412\n",
      "Epoch 179/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7295 - vae_r_loss: 13.3995 - vae_kl_loss: 9.3300\n",
      "Epoch 180/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7297 - vae_r_loss: 13.3942 - vae_kl_loss: 9.3355\n",
      "Epoch 181/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7346 - vae_r_loss: 13.4137 - vae_kl_loss: 9.3208\n",
      "Epoch 182/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7140 - vae_r_loss: 13.4003 - vae_kl_loss: 9.3137\n",
      "Epoch 183/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7161 - vae_r_loss: 13.4096 - vae_kl_loss: 9.3065\n",
      "Epoch 184/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7144 - vae_r_loss: 13.4014 - vae_kl_loss: 9.3130\n",
      "Epoch 185/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7504 - vae_r_loss: 13.4533 - vae_kl_loss: 9.2971\n",
      "Epoch 186/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7274 - vae_r_loss: 13.4391 - vae_kl_loss: 9.2883\n",
      "Epoch 187/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7251 - vae_r_loss: 13.4211 - vae_kl_loss: 9.3040\n",
      "Epoch 188/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7554 - vae_r_loss: 13.4404 - vae_kl_loss: 9.3150\n",
      "Epoch 189/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7276 - vae_r_loss: 13.4211 - vae_kl_loss: 9.3065\n",
      "Epoch 190/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6537 - vae_r_loss: 13.3529 - vae_kl_loss: 9.3008\n",
      "Epoch 191/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7388 - vae_r_loss: 13.4462 - vae_kl_loss: 9.2926\n",
      "Epoch 192/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7064 - vae_r_loss: 13.3968 - vae_kl_loss: 9.3096\n",
      "Epoch 193/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6647 - vae_r_loss: 13.3831 - vae_kl_loss: 9.2816\n",
      "Epoch 194/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7764 - vae_r_loss: 13.4754 - vae_kl_loss: 9.3010\n",
      "Epoch 195/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7836 - vae_r_loss: 13.4584 - vae_kl_loss: 9.3251\n",
      "Epoch 196/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7389 - vae_r_loss: 13.4126 - vae_kl_loss: 9.3263\n",
      "Epoch 197/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7620 - vae_r_loss: 13.4229 - vae_kl_loss: 9.3391\n",
      "Epoch 198/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7202 - vae_r_loss: 13.3863 - vae_kl_loss: 9.3338: 1s - loss: 22.7642\n",
      "Epoch 199/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7030 - vae_r_loss: 13.3970 - vae_kl_loss: 9.3060\n",
      "Epoch 200/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7605 - vae_r_loss: 13.4382 - vae_kl_loss: 9.3222\n",
      "Epoch 201/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7471 - vae_r_loss: 13.4128 - vae_kl_loss: 9.3343: 1s -\n",
      "Epoch 202/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7433 - vae_r_loss: 13.4118 - vae_kl_loss: 9.3315\n",
      "Epoch 203/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7104 - vae_r_loss: 13.3888 - vae_kl_loss: 9.3217\n",
      "Epoch 204/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7444 - vae_r_loss: 13.4265 - vae_kl_loss: 9.3179\n",
      "Epoch 205/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7818 - vae_r_loss: 13.4548 - vae_kl_loss: 9.3270\n",
      "Epoch 206/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7266 - vae_r_loss: 13.4138 - vae_kl_loss: 9.3128\n",
      "Epoch 207/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7208 - vae_r_loss: 13.4143 - vae_kl_loss: 9.3066\n",
      "Epoch 208/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6984 - vae_r_loss: 13.4132 - vae_kl_loss: 9.2852\n",
      "Epoch 209/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7880 - vae_r_loss: 13.5045 - vae_kl_loss: 9.2835\n",
      "Epoch 210/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7464 - vae_r_loss: 13.4401 - vae_kl_loss: 9.3063\n",
      "Epoch 211/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7106 - vae_r_loss: 13.4023 - vae_kl_loss: 9.3083\n",
      "Epoch 212/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7452 - vae_r_loss: 13.4539 - vae_kl_loss: 9.2913\n",
      "Epoch 213/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7346 - vae_r_loss: 13.4283 - vae_kl_loss: 9.3063\n",
      "Epoch 214/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7092 - vae_r_loss: 13.4098 - vae_kl_loss: 9.2993\n",
      "Epoch 215/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6747 - vae_r_loss: 13.3720 - vae_kl_loss: 9.3027\n",
      "Epoch 216/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6481 - vae_r_loss: 13.3711 - vae_kl_loss: 9.2769\n",
      "Epoch 217/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7158 - vae_r_loss: 13.4469 - vae_kl_loss: 9.2689\n",
      "Epoch 218/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6929 - vae_r_loss: 13.4021 - vae_kl_loss: 9.2908\n",
      "Epoch 219/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7330 - vae_r_loss: 13.4311 - vae_kl_loss: 9.3019\n",
      "Epoch 220/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6860 - vae_r_loss: 13.3930 - vae_kl_loss: 9.2930\n",
      "Epoch 221/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7301 - vae_r_loss: 13.4245 - vae_kl_loss: 9.3056\n",
      "Epoch 222/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7066 - vae_r_loss: 13.3974 - vae_kl_loss: 9.3091\n",
      "Epoch 223/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7349 - vae_r_loss: 13.4435 - vae_kl_loss: 9.2914\n",
      "Epoch 224/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7608 - vae_r_loss: 13.4463 - vae_kl_loss: 9.3145\n",
      "Epoch 225/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7739 - vae_r_loss: 13.4479 - vae_kl_loss: 9.3260\n",
      "Epoch 226/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7839 - vae_r_loss: 13.4549 - vae_kl_loss: 9.3289\n",
      "Epoch 227/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6965 - vae_r_loss: 13.3712 - vae_kl_loss: 9.3253\n",
      "Epoch 228/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7075 - vae_r_loss: 13.3974 - vae_kl_loss: 9.3101\n",
      "Epoch 229/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6665 - vae_r_loss: 13.3777 - vae_kl_loss: 9.2888\n",
      "Epoch 230/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7102 - vae_r_loss: 13.4113 - vae_kl_loss: 9.2989\n",
      "Epoch 231/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7534 - vae_r_loss: 13.4495 - vae_kl_loss: 9.3039\n",
      "Epoch 232/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7240 - vae_r_loss: 13.4128 - vae_kl_loss: 9.3111\n",
      "Epoch 233/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7245 - vae_r_loss: 13.4305 - vae_kl_loss: 9.2940\n",
      "Epoch 234/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7348 - vae_r_loss: 13.4277 - vae_kl_loss: 9.3071\n",
      "Epoch 235/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7233 - vae_r_loss: 13.4107 - vae_kl_loss: 9.3125\n",
      "Epoch 236/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7497 - vae_r_loss: 13.4318 - vae_kl_loss: 9.3179\n",
      "Epoch 237/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7205 - vae_r_loss: 13.3973 - vae_kl_loss: 9.3232\n",
      "Epoch 238/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7326 - vae_r_loss: 13.4163 - vae_kl_loss: 9.3162\n",
      "Epoch 239/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7380 - vae_r_loss: 13.4237 - vae_kl_loss: 9.3144\n",
      "Epoch 240/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7683 - vae_r_loss: 13.4510 - vae_kl_loss: 9.3173\n",
      "Epoch 241/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7767 - vae_r_loss: 13.4593 - vae_kl_loss: 9.3174\n",
      "Epoch 242/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.8098 - vae_r_loss: 13.4763 - vae_kl_loss: 9.3335\n",
      "Epoch 243/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7002 - vae_r_loss: 13.3651 - vae_kl_loss: 9.3351\n",
      "Epoch 244/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7271 - vae_r_loss: 13.3935 - vae_kl_loss: 9.3336\n",
      "Epoch 245/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7145 - vae_r_loss: 13.3987 - vae_kl_loss: 9.3158\n",
      "Epoch 246/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7354 - vae_r_loss: 13.4373 - vae_kl_loss: 9.2981\n",
      "Epoch 247/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7310 - vae_r_loss: 13.4199 - vae_kl_loss: 9.3111\n",
      "Epoch 248/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7055 - vae_r_loss: 13.3879 - vae_kl_loss: 9.3176\n",
      "Epoch 249/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.6578 - vae_r_loss: 13.3640 - vae_kl_loss: 9.2937\n",
      "Epoch 250/250\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 22.7227 - vae_r_loss: 13.4174 - vae_kl_loss: 9.3053\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0000005\n",
    "R_LOSS_FACTOR = 1000\n",
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 250\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "\n",
    "vae.train(\n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")\n",
    "vae.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test again\n",
    "\n",
    "\n",
    "vae = VariationalAutoencoder(\n",
    "    input_dim = (32,32,3)\n",
    "    , encoder_conv_filters = [32,64,64, 64]\n",
    "    , encoder_conv_kernel_size = [3,3,3,3]\n",
    "    , encoder_conv_strides = [1,2,2,1]\n",
    "    , decoder_conv_t_filters = [64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 2\n",
    ")\n",
    "\n",
    "#vae.load_weights(\"C:\\\\Users\\\\adoerr\\\\Desktop\\\\Machine Learning\\\\Aufgabe 2\\\\run\\\\weights\\\\weights-033-34.17.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a61ae0e07702>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mreconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testindex = 4999\n",
    "img = x_train[testindex]\n",
    "#print(\"Correct label =\",label_name(y_test_numerical[testindex]))\n",
    "print(plt.imshow(img))\n",
    "img = img.reshape((1,) + img.shape)\n",
    "\n",
    "encoding = vae.encoder.predict(img)\n",
    "reconst = vae.decoder.predict(encoding)[0].squeeze()\n",
    "\n",
    "print(encoding)\n",
    "\n",
    "#filepath = os.path.join(self.run_folder, 'images','img_' + str(self.epoch).zfill(3) + '_' + str(batch) + '.jpg')\n",
    "#print(\"Prediction:\",vae.encoder.predict(img))\n",
    "#print(\"Prediction:\",vae.decoder.predict(vae.encoder.predict(img)))\n",
    "#print(vae.decoder.predict(vae.encoder.predict(img)).type\n",
    "#print(vae.encoder.predict)\n",
    "#plt.imshow(vae.decoder.predict(vae.encoder.predict(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.imshow(reconst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "testindex = 51\n",
    "img = x_test[testindex]\n",
    "plt.imshow(img)\n",
    "print(label_name(y_test_numerical[testindex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
